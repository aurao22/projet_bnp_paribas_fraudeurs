{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: RGB(255,114,0);\" >\n",
    "<div>\n",
    "<img src=\"img/fraudeur_-_BNPP_PF_-_finale.jpg\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "# PROJET - Comment démasquer les fraudeurs ? <mark>EDA toutes les données</mark>\n",
    "</div>\n",
    "\n",
    "par BNP Paribas PF\n",
    "\n",
    "Lien vers le challenge : https://challengedata.ens.fr/participants/challenges/104/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Blue; padding: 15px;\" >\n",
    "\n",
    "## 1.CHARGEMENT des données\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current execution path : c:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\n",
      "Dataset path : c:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\dataset\n"
     ]
    }
   ],
   "source": [
    "from os import getcwd\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pr_auc_score_SB05ixL import *\n",
    "from bnp_paribas import *\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "#                               MAIN\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "verbose = 1\n",
    "\n",
    "target = \"fraud_flag\"\n",
    "\n",
    "# Récupère le répertoire du programme\n",
    "execution_path = getcwd().split(\"projet_bnp_paribas_fraudeurs\")[0]\n",
    "execution_path = join(execution_path, 'projet_bnp_paribas_fraudeurs')\n",
    "\n",
    "data_set_path = join(execution_path, 'dataset')\n",
    "data_set_train_file_name = join(data_set_path, \"train_complete_encoded_hyper_light_2023_01_19.csv\")\n",
    "\n",
    "print(f\"Current execution path : {execution_path}\")\n",
    "print(f\"Dataset path : {data_set_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Chargement des données pré-traitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_splited_data   ]\tINFO  \u001b[6;30;42mIN PROGRESS...\u001b[0m                          \n",
      "[load_splited_data   ]\tINFO  over BorderlineSMOTE Loading X_train...                          \n"
     ]
    }
   ],
   "source": [
    "# [load_splited_data   ]\tINFO  Chargement des données train sources...                          \n",
    "# [load_splited_data   ]\tINFO  (92790, 1981) train données chargées                          \n",
    "# [load_splited_data   ]\tINFO  Séparation de X et y...                          \n",
    "# [load_splited_data   ]\tINFO  split du dataset_path...                          \n",
    "# [load_splited_data   ]\tINFO  5 dataset LOAD                          \n",
    "# [load_splited_data   ]\tINFO  (74232, 1980) / (18558, 1980) \n",
    "random_state = 42\n",
    "dataset_dict = load_splited_data(dataset_path=data_set_train_file_name,over_name=\"BorderlineSMOTE\", random_state = random_state, save_it=True, force=False, verbose=verbose)\n",
    "\n",
    "X_train, X_test, y_train, y_test, train_origin = dataset_dict.get(\"X_train\", None), dataset_dict.get(\"X_test\", None), dataset_dict.get(\"y_train\", None), dataset_dict.get(\"y_test\", None), dataset_dict.get(\"train_origin\", None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Chargement du set de test officiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92790, 1981) test données chargées\n",
      "(92790, 1982) test données mises à jour\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>Nb_of_items</th>\n",
       "      <th>item_BED LINEN_nb</th>\n",
       "      <th>item_BED LINEN_cash</th>\n",
       "      <th>item_BATHROOM_nb</th>\n",
       "      <th>item_BATHROOM_cash</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_nb</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_cash</th>\n",
       "      <th>item_TOYS_nb</th>\n",
       "      <th>...</th>\n",
       "      <th>make_BLUEBELLA_cash</th>\n",
       "      <th>make_ROLSER_nb</th>\n",
       "      <th>make_ROLSER_cash</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_nb</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_cash</th>\n",
       "      <th>make_TEMPLE ISLAND_nb</th>\n",
       "      <th>make_TEMPLE ISLAND_cash</th>\n",
       "      <th>make_GHD_nb</th>\n",
       "      <th>make_GHD_cash</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>85517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>51113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>83008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>78712</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>77846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92785</th>\n",
       "      <td>0</td>\n",
       "      <td>21243</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92786</th>\n",
       "      <td>0</td>\n",
       "      <td>45891</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92787</th>\n",
       "      <td>0</td>\n",
       "      <td>42613</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1727.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92788</th>\n",
       "      <td>0</td>\n",
       "      <td>43567</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92789</th>\n",
       "      <td>0</td>\n",
       "      <td>68268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>799.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92790 rows × 1982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     ID  Nb_of_items  item_BED LINEN_nb  item_BED LINEN_cash  \\\n",
       "index                                                                      \n",
       "0          0  85517          1.0                0.0                  0.0   \n",
       "1          0  51113          1.0                0.0                  0.0   \n",
       "2          0  83008          1.0                0.0                  0.0   \n",
       "3          0  78712          2.0                0.0                  0.0   \n",
       "4          0  77846          1.0                0.0                  0.0   \n",
       "...      ...    ...          ...                ...                  ...   \n",
       "92785      0  21243          2.0                0.0                  0.0   \n",
       "92786      0  45891          1.0                0.0                  0.0   \n",
       "92787      0  42613          3.0                0.0                  0.0   \n",
       "92788      0  43567          2.0                0.0                  0.0   \n",
       "92789      0  68268          1.0                0.0                  0.0   \n",
       "\n",
       "       item_BATHROOM_nb  item_BATHROOM_cash  \\\n",
       "index                                         \n",
       "0                   0.0                 0.0   \n",
       "1                   0.0                 0.0   \n",
       "2                   0.0                 0.0   \n",
       "3                   0.0                 0.0   \n",
       "4                   0.0                 0.0   \n",
       "...                 ...                 ...   \n",
       "92785               0.0                 0.0   \n",
       "92786               0.0                 0.0   \n",
       "92787               0.0                 0.0   \n",
       "92788               0.0                 0.0   \n",
       "92789               0.0                 0.0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_nb  \\\n",
       "index                                         \n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "92785                                   0.0   \n",
       "92786                                   0.0   \n",
       "92787                                   0.0   \n",
       "92788                                   0.0   \n",
       "92789                                   0.0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_cash  item_TOYS_nb  ...  \\\n",
       "index                                                        ...   \n",
       "0                                         0.0           0.0  ...   \n",
       "1                                         0.0           0.0  ...   \n",
       "2                                         0.0           0.0  ...   \n",
       "3                                         0.0           0.0  ...   \n",
       "4                                         0.0           0.0  ...   \n",
       "...                                       ...           ...  ...   \n",
       "92785                                     0.0           0.0  ...   \n",
       "92786                                     0.0           0.0  ...   \n",
       "92787                                     0.0           0.0  ...   \n",
       "92788                                     0.0           0.0  ...   \n",
       "92789                                     0.0           0.0  ...   \n",
       "\n",
       "       make_BLUEBELLA_cash  make_ROLSER_nb  make_ROLSER_cash  \\\n",
       "index                                                          \n",
       "0                      0.0             0.0               0.0   \n",
       "1                      0.0             0.0               0.0   \n",
       "2                      0.0             0.0               0.0   \n",
       "3                      0.0             0.0               0.0   \n",
       "4                      0.0             0.0               0.0   \n",
       "...                    ...             ...               ...   \n",
       "92785                  0.0             0.0               0.0   \n",
       "92786                  0.0             0.0               0.0   \n",
       "92787                  0.0             0.0               0.0   \n",
       "92788                  0.0             0.0               0.0   \n",
       "92789                  0.0             0.0               0.0   \n",
       "\n",
       "       make_DARTINGTON CRYSTAL_nb  make_DARTINGTON CRYSTAL_cash  \\\n",
       "index                                                             \n",
       "0                             0.0                           0.0   \n",
       "1                             0.0                           0.0   \n",
       "2                             0.0                           0.0   \n",
       "3                             0.0                           0.0   \n",
       "4                             0.0                           0.0   \n",
       "...                           ...                           ...   \n",
       "92785                         0.0                           0.0   \n",
       "92786                         0.0                           0.0   \n",
       "92787                         0.0                           0.0   \n",
       "92788                         0.0                           0.0   \n",
       "92789                         0.0                           0.0   \n",
       "\n",
       "       make_TEMPLE ISLAND_nb  make_TEMPLE ISLAND_cash  make_GHD_nb  \\\n",
       "index                                                                \n",
       "0                        0.0                      0.0          0.0   \n",
       "1                        0.0                      0.0          0.0   \n",
       "2                        0.0                      0.0          0.0   \n",
       "3                        0.0                      0.0          0.0   \n",
       "4                        0.0                      0.0          0.0   \n",
       "...                      ...                      ...          ...   \n",
       "92785                    0.0                      0.0          0.0   \n",
       "92786                    0.0                      0.0          0.0   \n",
       "92787                    0.0                      0.0          0.0   \n",
       "92788                    0.0                      0.0          0.0   \n",
       "92789                    0.0                      0.0          0.0   \n",
       "\n",
       "       make_GHD_cash  amount  \n",
       "index                         \n",
       "0                0.0   889.0  \n",
       "1                0.0   409.0  \n",
       "2                0.0  1399.0  \n",
       "3                0.0   808.0  \n",
       "4                0.0  1199.0  \n",
       "...              ...     ...  \n",
       "92785            0.0   306.0  \n",
       "92786            0.0   898.0  \n",
       "92787            0.0  1727.0  \n",
       "92788            0.0  3198.0  \n",
       "92789            0.0   799.0  \n",
       "\n",
       "[92790 rows x 1982 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file_name= \"test_complete_encoded_2023_01_19.csv\"\n",
    "data_set_test_file_name = data_set_train_file_name.replace(\"train_complete_hyper\", \"test_complete\")\n",
    "test_origin = load_test_df(file_path=data_set_test_file_name, train_columns=X_train.columns, verbose=verbose)\n",
    "dataset_dict[\"test_origin\"] = test_origin\n",
    "test_origin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Chargement des scores déjà enregistrés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>Features</th>\n",
       "      <th>Add Data</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>pr_auc_score TEST perso</th>\n",
       "      <th>pr_auc_score TEST officiel</th>\n",
       "      <th>Params</th>\n",
       "      <th>Commentaire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-20 16:16</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>Items</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.986259</td>\n",
       "      <td>0.093033</td>\n",
       "      <td>0.078557</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>Sans ajout de données</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-21 17:29</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>Items</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.925989</td>\n",
       "      <td>0.879887</td>\n",
       "      <td>0.068491</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>AVEC ajout de données sur tout le dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-21 17:31</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Items</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.733608</td>\n",
       "      <td>0.657288</td>\n",
       "      <td>0.032113</td>\n",
       "      <td>penalty=\"l2\", fit_intercept=True,solver='libli...</td>\n",
       "      <td>AVEC ajout de données sur tout le dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-20 15:29</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Items</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985074</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>penalty=\"l2\", fit_intercept=True,solver='libli...</td>\n",
       "      <td>Sans ajout de données</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-21 17:45</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.932220</td>\n",
       "      <td>0.888196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>AVEC ajout de données sur tout le dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-21 17:40</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.726748</td>\n",
       "      <td>0.650713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty=\"l2\", fit_intercept=True,solver='libli...</td>\n",
       "      <td>AVEC ajout de données sur tout le dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-21 17:35</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.986152</td>\n",
       "      <td>0.093013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>SANS ajout de données</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 14:59</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985936</td>\n",
       "      <td>0.078879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 16:56</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985667</td>\n",
       "      <td>0.070795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>add amount column</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 17:04</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.931674</td>\n",
       "      <td>0.068321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>Add amount and Add data on train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 17:53</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>BorderlineSMOTE</td>\n",
       "      <td>0.980440</td>\n",
       "      <td>0.065619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>Amount and Add data on train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-13 11:00</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.893523</td>\n",
       "      <td>0.060563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>AVEC ajout de données sur Train only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 15:45</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.928387</td>\n",
       "      <td>0.059118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>Add data on train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 17:52</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>BorderlineSMOTE</td>\n",
       "      <td>0.634336</td>\n",
       "      <td>0.028390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty='l2', fit_intercept=True,solver='libli...</td>\n",
       "      <td>Amount and Add data on train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 15:42</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.606261</td>\n",
       "      <td>0.026763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty='l2', fit_intercept=True,solver='libli...</td>\n",
       "      <td>Add data on train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-13 10:00</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.565147</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty=\"l2\", fit_intercept=True,solver='libli...</td>\n",
       "      <td>AVEC ajout de données sur Train only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 17:03</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.598610</td>\n",
       "      <td>0.026163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty='l2', fit_intercept=True,solver='libli...</td>\n",
       "      <td>Add amount and Add data on train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 10:55</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.545425</td>\n",
       "      <td>0.025792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty=l2, fit_intercept=True,solver='liblinear'</td>\n",
       "      <td>Add data on Train on minority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-21 17:30</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.984966</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty=\"l2\", fit_intercept=True,solver='libli...</td>\n",
       "      <td>SANS ajout de données</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 16:52</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.984858</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty='l2', fit_intercept=True,solver='libli...</td>\n",
       "      <td>add amount column</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 18:56</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler amount less</td>\n",
       "      <td>0.866580</td>\n",
       "      <td>0.014306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty='l2', fit_intercept=True,solver='libli...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 19:26</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>SMOTE_minority amount less</td>\n",
       "      <td>0.844703</td>\n",
       "      <td>0.014233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty='l2', fit_intercept=True,solver='libli...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Modèle Features                       Add Data  \\\n",
       "date                                                                           \n",
       "2023-01-20 16:16      LGBMClassifier    Items                            NaN   \n",
       "2023-01-21 17:29      LGBMClassifier    Items              RandomOverSampler   \n",
       "2023-01-21 17:31  LogisticRegression    Items              RandomOverSampler   \n",
       "2023-01-20 15:29  LogisticRegression    Items                            NaN   \n",
       "2023-01-21 17:45      LGBMClassifier      ALL              RandomOverSampler   \n",
       "2023-01-21 17:40  LogisticRegression      ALL              RandomOverSampler   \n",
       "2023-01-21 17:35      LGBMClassifier      ALL                            NaN   \n",
       "2023-02-14 14:59      LGBMClassifier      ALL                            NaN   \n",
       "2023-02-14 16:56      LGBMClassifier      ALL                            NaN   \n",
       "2023-02-14 17:04      LGBMClassifier      ALL              RandomOverSampler   \n",
       "2023-02-14 17:53      LGBMClassifier      ALL                BorderlineSMOTE   \n",
       "2023-02-13 11:00      LGBMClassifier      ALL              RandomOverSampler   \n",
       "2023-02-14 15:45      LGBMClassifier      ALL              RandomOverSampler   \n",
       "2023-02-14 17:52  LogisticRegression      ALL                BorderlineSMOTE   \n",
       "2023-02-14 15:42  LogisticRegression      ALL              RandomOverSampler   \n",
       "2023-02-13 10:00  LogisticRegression      ALL              RandomOverSampler   \n",
       "2023-02-14 17:03  LogisticRegression      ALL              RandomOverSampler   \n",
       "2023-02-14 10:55  LogisticRegression      ALL                          SMOTE   \n",
       "2023-01-21 17:30  LogisticRegression      ALL                            NaN   \n",
       "2023-02-14 16:52  LogisticRegression      ALL                            NaN   \n",
       "2023-02-14 18:56  LogisticRegression      ALL  RandomOverSampler amount less   \n",
       "2023-02-14 19:26  LogisticRegression      ALL     SMOTE_minority amount less   \n",
       "\n",
       "                  Accuracy Score  pr_auc_score TEST perso  \\\n",
       "date                                                        \n",
       "2023-01-20 16:16        0.986259                 0.093033   \n",
       "2023-01-21 17:29        0.925989                 0.879887   \n",
       "2023-01-21 17:31        0.733608                 0.657288   \n",
       "2023-01-20 15:29        0.985074                 0.014657   \n",
       "2023-01-21 17:45        0.932220                 0.888196   \n",
       "2023-01-21 17:40        0.726748                 0.650713   \n",
       "2023-01-21 17:35        0.986152                 0.093013   \n",
       "2023-02-14 14:59        0.985936                 0.078879   \n",
       "2023-02-14 16:56        0.985667                 0.070795   \n",
       "2023-02-14 17:04        0.931674                 0.068321   \n",
       "2023-02-14 17:53        0.980440                 0.065619   \n",
       "2023-02-13 11:00        0.893523                 0.060563   \n",
       "2023-02-14 15:45        0.928387                 0.059118   \n",
       "2023-02-14 17:52        0.634336                 0.028390   \n",
       "2023-02-14 15:42        0.606261                 0.026763   \n",
       "2023-02-13 10:00        0.565147                 0.026700   \n",
       "2023-02-14 17:03        0.598610                 0.026163   \n",
       "2023-02-14 10:55        0.545425                 0.025792   \n",
       "2023-01-21 17:30        0.984966                 0.014657   \n",
       "2023-02-14 16:52        0.984858                 0.014657   \n",
       "2023-02-14 18:56        0.866580                 0.014306   \n",
       "2023-02-14 19:26        0.844703                 0.014233   \n",
       "\n",
       "                  pr_auc_score TEST officiel  \\\n",
       "date                                           \n",
       "2023-01-20 16:16                    0.078557   \n",
       "2023-01-21 17:29                    0.068491   \n",
       "2023-01-21 17:31                    0.032113   \n",
       "2023-01-20 15:29                    0.016812   \n",
       "2023-01-21 17:45                    0.000000   \n",
       "2023-01-21 17:40                    0.000000   \n",
       "2023-01-21 17:35                    0.000000   \n",
       "2023-02-14 14:59                    0.000000   \n",
       "2023-02-14 16:56                    0.000000   \n",
       "2023-02-14 17:04                    0.000000   \n",
       "2023-02-14 17:53                    0.000000   \n",
       "2023-02-13 11:00                    0.000000   \n",
       "2023-02-14 15:45                    0.000000   \n",
       "2023-02-14 17:52                    0.000000   \n",
       "2023-02-14 15:42                    0.000000   \n",
       "2023-02-13 10:00                    0.000000   \n",
       "2023-02-14 17:03                    0.000000   \n",
       "2023-02-14 10:55                    0.000000   \n",
       "2023-01-21 17:30                    0.000000   \n",
       "2023-02-14 16:52                    0.000000   \n",
       "2023-02-14 18:56                    0.000000   \n",
       "2023-02-14 19:26                    0.000000   \n",
       "\n",
       "                                                             Params  \\\n",
       "date                                                                  \n",
       "2023-01-20 16:16  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-01-21 17:29  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-01-21 17:31  penalty=\"l2\", fit_intercept=True,solver='libli...   \n",
       "2023-01-20 15:29  penalty=\"l2\", fit_intercept=True,solver='libli...   \n",
       "2023-01-21 17:45  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-01-21 17:40  penalty=\"l2\", fit_intercept=True,solver='libli...   \n",
       "2023-01-21 17:35  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-14 14:59  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-14 16:56  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-14 17:04  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-14 17:53  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-13 11:00  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-14 15:45  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-14 17:52  penalty='l2', fit_intercept=True,solver='libli...   \n",
       "2023-02-14 15:42  penalty='l2', fit_intercept=True,solver='libli...   \n",
       "2023-02-13 10:00  penalty=\"l2\", fit_intercept=True,solver='libli...   \n",
       "2023-02-14 17:03  penalty='l2', fit_intercept=True,solver='libli...   \n",
       "2023-02-14 10:55  penalty=l2, fit_intercept=True,solver='liblinear'   \n",
       "2023-01-21 17:30  penalty=\"l2\", fit_intercept=True,solver='libli...   \n",
       "2023-02-14 16:52  penalty='l2', fit_intercept=True,solver='libli...   \n",
       "2023-02-14 18:56  penalty='l2', fit_intercept=True,solver='libli...   \n",
       "2023-02-14 19:26  penalty='l2', fit_intercept=True,solver='libli...   \n",
       "\n",
       "                                                Commentaire  \n",
       "date                                                         \n",
       "2023-01-20 16:16                      Sans ajout de données  \n",
       "2023-01-21 17:29  AVEC ajout de données sur tout le dataset  \n",
       "2023-01-21 17:31  AVEC ajout de données sur tout le dataset  \n",
       "2023-01-20 15:29                      Sans ajout de données  \n",
       "2023-01-21 17:45  AVEC ajout de données sur tout le dataset  \n",
       "2023-01-21 17:40  AVEC ajout de données sur tout le dataset  \n",
       "2023-01-21 17:35                      SANS ajout de données  \n",
       "2023-02-14 14:59                                        NaN  \n",
       "2023-02-14 16:56                          add amount column  \n",
       "2023-02-14 17:04           Add amount and Add data on train  \n",
       "2023-02-14 17:53               Amount and Add data on train  \n",
       "2023-02-13 11:00       AVEC ajout de données sur Train only  \n",
       "2023-02-14 15:45                          Add data on train  \n",
       "2023-02-14 17:52               Amount and Add data on train  \n",
       "2023-02-14 15:42                          Add data on train  \n",
       "2023-02-13 10:00       AVEC ajout de données sur Train only  \n",
       "2023-02-14 17:03           Add amount and Add data on train  \n",
       "2023-02-14 10:55              Add data on Train on minority  \n",
       "2023-01-21 17:30                      SANS ajout de données  \n",
       "2023-02-14 16:52                          add amount column  \n",
       "2023-02-14 18:56                                        NaN  \n",
       "2023-02-14 19:26                                        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_path = r'C:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\dataset\\score.csv'\n",
    "scores = load_scores(score_path=score_path, save_it=False, verbose=verbose)\n",
    "print(scores.shape)\n",
    "scores.sort_values([\"pr_auc_score TEST officiel\",\"pr_auc_score TEST perso\"], ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Blue; padding: 15px;\" >\n",
    "\n",
    "## 3.Modèles\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Green; padding: 7px;\" >\n",
    "\n",
    "### 3.1. Essai premier modèle sur item uniquement sans traitement\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### 3.1.1. LogisticRegression\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_model         ]\tINFO  accuracy score : 0.9848582821424723, pr_auc score : 0.014656751805151417                          \n",
      "[train_model         ]\tINFO  Prediction for test orgine...                          \n"
     ]
    }
   ],
   "source": [
    "# accuracy score : 0.9848043970255416, pr_auc score : 0.014656751805151417\n",
    "# accuracy score : 0.9848582821424723, pr_auc score : 0.014656751805151417\n",
    "my_fist_model, n_scores = train_LogisticRegression(dataset_dict=dataset_dict, data_set_path=data_set_path, \n",
    "                            scores=scores, score_path=score_path, \n",
    "                            features=\"ALL\", add_data=np.nan,commentaire=\"add amount column\", \n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = n_scores\n",
    "save_score(n_scores, score_path=score_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### 3.1.2. LGBMClassifier\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_model         ]\tINFO  accuracy score : 0.9856665588964328, pr_auc score : 0.07079502735462112                          \n",
      "[train_model         ]\tINFO  Prediction for test orgine...                          \n"
     ]
    }
   ],
   "source": [
    "# previously       0.9861515249488091 and 0.09301333707479051\n",
    "# accuracy score : 0.9859359844810863, pr_auc score : 0.07887944011003084\n",
    "# accuracy score : 0.9856665588964328, pr_auc score : 0.07079502735462112\n",
    "lgb_classifier, n_scores = train_LGBMClassifier(dataset_dict=dataset_dict, data_set_path=data_set_path, \n",
    "                            scores=scores, score_path=score_path, \n",
    "                            features=\"ALL\", add_data=np.nan,commentaire=\"add amount column\", \n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = n_scores\n",
    "save_score(n_scores, score_path=score_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Blue; padding: 15px;\" >\n",
    "\n",
    "## 4.Test des models avec les données ajoutées\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict_over = deepcopy(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for over_name in OVERED_DATASET_FILE_NAME.keys():\n",
    "    # Modèle\tFeatures\tAdd Data\n",
    "    run_logistic = scores[(scores[\"Add Data\"] == over_name)&(scores[\"Modèle\"] == \"LogisticRegression\")].shape[0] == 0\n",
    "    run_sqbmc    = scores[(scores[\"Add Data\"] == over_name)&(scores[\"Modèle\"] == \"LGBMClassifier\")].shape[0] == 0\n",
    "\n",
    "    if run_logistic or run_sqbmc:\n",
    "        print(f\"{over_name} logistic = {run_logistic} and sqbmc = {run_sqbmc} \\t{surligne_text('processing...', 'blue')}\")\n",
    "        # Chargement des données\n",
    "        file_name = OVERED_DATASET_FILE_NAME.get(over_name)\n",
    "        \n",
    "        path = join(data_set_path,file_name)\n",
    "        if exists(path):\n",
    "            dataset_over = load_over_dataset(path, verbose=verbose)\n",
    "                        \n",
    "            if dataset_over is not None:\n",
    "                print(f\"{over_name} \\t ---> {surligne_text('pre-processing...', 'blue')}\")\n",
    "                \n",
    "                dataset_over = add_amounts(x_df_input=dataset_over, verbose=verbose)\n",
    "                y_train_over = complete_y_cols(dataset_over, y_param=dataset_over[target])\n",
    "                X_train_over = dataset_over.drop(target, axis=1)\n",
    "\n",
    "                dataset_dict_over['X_train'] = X_train_over\n",
    "                dataset_dict_over['y_train'] = y_train_over\n",
    "\n",
    "                if run_logistic:\n",
    "                    try:\n",
    "                        model, n_scores = train_LogisticRegression(dataset_dict=dataset_dict_over, data_set_path=data_set_path, \n",
    "                                        scores=scores, score_path=score_path, \n",
    "                                        features=\"ALL\", add_data=over_name,\n",
    "                                        verbose=verbose)\n",
    "                        save_score(n_scores, score_path=score_path)\n",
    "                        scores = n_scores\n",
    "                        print(f\"{over_name} processing logistic = \\t{surligne_text('DONE')}\")\n",
    "                    except Exception as error:\n",
    "                        print(f\"{over_name} processing logistic = \\t{surligne_text('FAIL', 'red')} : {error}\")\n",
    "                \n",
    "                if run_sqbmc:\n",
    "                    try:\n",
    "                        lgb_classifier, n_scores = train_LGBMClassifier(dataset_dict=dataset_dict_over, data_set_path=data_set_path, \n",
    "                                        scores=scores, score_path=score_path, \n",
    "                                        features=\"ALL\",  add_data=over_name,\n",
    "                                        verbose=verbose)\n",
    "                        save_score(n_scores, score_path=score_path)\n",
    "                        scores = n_scores\n",
    "                        print(f\"{over_name} processing sqbmc = \\t{surligne_text('DONE')}\")\n",
    "                    except Exception as error:\n",
    "                        print(f\"{over_name} processing sqbmc = \\t{surligne_text('FAIL', 'red')} : {error}\")\n",
    "    else:\n",
    "        print(f\"{over_name} \\t\\t {surligne_text('DONE')}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Green; padding: 7px;\" >\n",
    "\n",
    "### 4.2. Ajout de données avec SMOTE :  Synthetic Minority Oversampling Technique\n",
    "</div>\n",
    "\n",
    "https://kobia.fr/imbalanced-data-et-machine-learning/\n",
    "\n",
    "> Le sur-échantillonnage synthétique (SMOTE pour Synthetic Minority Oversampling Technique) est une méthode plus avancée, qui produit des observations minoritaires ressemblantes mais distinctes de celles déjà existantes. Pour plus de précisions, vous pouvez consulter notre article dédié au SMOTE.\n",
    "\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[over_SMOTE          ]\tINFO  (146370, 1982), (146370,)                          \n",
      "[over_SMOTE          ]\tINFO  c:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\dataset\\train_complete_OVER_SMOTE_minority_encoded_hyper_light_2023_01_19.csv \u001b[6;30;42mSAVE\u001b[0m                          \n"
     ]
    }
   ],
   "source": [
    "dataset_over_SMOTE = over_dataset_with_SMOTE(X_train,y_train, data_set_path=data_set_train_file_name, \n",
    "                     sampling_strategy='minority', random_state=random_state, target = target, verbose=verbose)\n",
    "\n",
    "X_train_over = dataset_over_SMOTE.drop(target, axis=1)\n",
    "y_train_over = complete_y_cols(X_train_over, y_param=dataset_over_SMOTE[target])\n",
    "\n",
    "dataset_dict_over_SMOTE = deepcopy(dataset_dict)\n",
    "dataset_dict_over_SMOTE['X_train'] = X_train_over\n",
    "dataset_dict_over_SMOTE['y_train'] = y_train_over"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### M.4.2. LogisticRegression\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5454251535725833, 0.025792401467034952\n",
    "# Fail not enought memory (2.16 GiB)\n",
    "model, n_scores = train_LogisticRegression(dataset_dict=dataset_dict_over_SMOTE, data_set_path=data_set_path, \n",
    "                            scores=scores, score_path=score_path, \n",
    "                            features=\"ALL\", add_data=\"SMOTE\",commentaire=\"Amount and Add data on train\", \n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = n_scores\n",
    "save_score(n_scores, score_path=score_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### M.4.3. LGBMClassifier\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.16 GiB for an array with shape (1982, 146370) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\bnp_paribas_EDA_all.ipynb Cellule 79\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/WORK/workspace-ia/PROJETS/projet_bnp_paribas_fraudeurs/bnp_paribas_EDA_all.ipynb#Y260sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 0.9706864963896972 and fail\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/WORK/workspace-ia/PROJETS/projet_bnp_paribas_fraudeurs/bnp_paribas_EDA_all.ipynb#Y260sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m lgb_classifier, n_scores \u001b[39m=\u001b[39m train_LGBMClassifier(dataset_dict\u001b[39m=\u001b[39;49mdataset_dict_over_SMOTE, data_set_path\u001b[39m=\u001b[39;49mdata_set_path, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/WORK/workspace-ia/PROJETS/projet_bnp_paribas_fraudeurs/bnp_paribas_EDA_all.ipynb#Y260sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                             scores\u001b[39m=\u001b[39;49mscores, score_path\u001b[39m=\u001b[39;49mscore_path, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/WORK/workspace-ia/PROJETS/projet_bnp_paribas_fraudeurs/bnp_paribas_EDA_all.ipynb#Y260sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                             features\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mALL\u001b[39;49m\u001b[39m\"\u001b[39;49m,  add_data\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSMOTE\u001b[39;49m\u001b[39m\"\u001b[39;49m,commentaire\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mAmount and Add data on train\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/WORK/workspace-ia/PROJETS/projet_bnp_paribas_fraudeurs/bnp_paribas_EDA_all.ipynb#Y260sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                             verbose\u001b[39m=\u001b[39;49mverbose)\n",
      "File \u001b[1;32mc:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\bnp_paribas.py:489\u001b[0m, in \u001b[0;36mtrain_LGBMClassifier\u001b[1;34m(dataset_dict, data_set_path, scores, score_path, features, add_data, commentaire, verbose)\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[39mreturn\u001b[39;00m model, n_scores\n\u001b[0;32m    487\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m    488\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_LogisticRegression\u001b[39m(dataset_dict, data_set_path, \n\u001b[1;32m--> 489\u001b[0m                             scores, score_path, \n\u001b[0;32m    490\u001b[0m                             features\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mALL\u001b[39m\u001b[39m\"\u001b[39m, add_data\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan,commentaire\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan, \n\u001b[0;32m    491\u001b[0m                             verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m    493\u001b[0m     \u001b[39mif\u001b[39;00m verbose\u001b[39m>\u001b[39m\u001b[39m1\u001b[39m:\u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel creation...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    494\u001b[0m     my_fist_model \u001b[39m=\u001b[39m LogisticRegression(penalty\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m\"\u001b[39m, fit_intercept\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\bnp_paribas.py:430\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, model_name, dataset_dict, data_set_path, scores, score_path, params, features, add_data, commentaire, target, verbose)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop_numeroted_data_col\u001b[39m(df, cols_name, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m    429\u001b[0m     short_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdrop_numeroted_data_col\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 430\u001b[0m     n_df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    431\u001b[0m     nb_col_droped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \n\u001b[0;32m    432\u001b[0m     \u001b[39mif\u001b[39;00m verbose\u001b[39m>\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\lightgbm\\sklearn.py:967\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    964\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m             valid_sets[i] \u001b[39m=\u001b[39m (valid_x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_le\u001b[39m.\u001b[39mtransform(valid_y))\n\u001b[1;32m--> 967\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, _y, sample_weight\u001b[39m=\u001b[39;49msample_weight, init_score\u001b[39m=\u001b[39;49minit_score, eval_set\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[0;32m    968\u001b[0m             eval_names\u001b[39m=\u001b[39;49meval_names, eval_sample_weight\u001b[39m=\u001b[39;49meval_sample_weight,\n\u001b[0;32m    969\u001b[0m             eval_class_weight\u001b[39m=\u001b[39;49meval_class_weight, eval_init_score\u001b[39m=\u001b[39;49meval_init_score,\n\u001b[0;32m    970\u001b[0m             eval_metric\u001b[39m=\u001b[39;49meval_metric, early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m    971\u001b[0m             verbose\u001b[39m=\u001b[39;49mverbose, feature_name\u001b[39m=\u001b[39;49mfeature_name, categorical_feature\u001b[39m=\u001b[39;49mcategorical_feature,\n\u001b[0;32m    972\u001b[0m             callbacks\u001b[39m=\u001b[39;49mcallbacks, init_model\u001b[39m=\u001b[39;49minit_model)\n\u001b[0;32m    973\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\lightgbm\\sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    745\u001b[0m evals_result \u001b[39m=\u001b[39m {}\n\u001b[0;32m    746\u001b[0m callbacks\u001b[39m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m    749\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    750\u001b[0m     train_set\u001b[39m=\u001b[39;49mtrain_set,\n\u001b[0;32m    751\u001b[0m     num_boost_round\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_estimators,\n\u001b[0;32m    752\u001b[0m     valid_sets\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[0;32m    753\u001b[0m     valid_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[0;32m    754\u001b[0m     fobj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fobj,\n\u001b[0;32m    755\u001b[0m     feval\u001b[39m=\u001b[39;49meval_metrics_callable,\n\u001b[0;32m    756\u001b[0m     init_model\u001b[39m=\u001b[39;49minit_model,\n\u001b[0;32m    757\u001b[0m     feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[0;32m    758\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[0;32m    759\u001b[0m )\n\u001b[0;32m    761\u001b[0m \u001b[39mif\u001b[39;00m evals_result:\n\u001b[0;32m    762\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evals_result \u001b[39m=\u001b[39m evals_result\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\lightgbm\\engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39m# construct booster\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m     booster \u001b[39m=\u001b[39m Booster(params\u001b[39m=\u001b[39;49mparams, train_set\u001b[39m=\u001b[39;49mtrain_set)\n\u001b[0;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    273\u001b[0m         booster\u001b[39m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\lightgbm\\basic.py:2605\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_network(\n\u001b[0;32m   2599\u001b[0m         machines\u001b[39m=\u001b[39mmachines,\n\u001b[0;32m   2600\u001b[0m         local_listen_port\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mlocal_listen_port\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   2601\u001b[0m         listen_time_out\u001b[39m=\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_out\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m120\u001b[39m),\n\u001b[0;32m   2602\u001b[0m         num_machines\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mnum_machines\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2603\u001b[0m     )\n\u001b[0;32m   2604\u001b[0m \u001b[39m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 2605\u001b[0m train_set\u001b[39m.\u001b[39;49mconstruct()\n\u001b[0;32m   2606\u001b[0m \u001b[39m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   2607\u001b[0m params\u001b[39m.\u001b[39mupdate(train_set\u001b[39m.\u001b[39mget_params())\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\lightgbm\\basic.py:1815\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1812\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_init_score_by_predictor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predictor, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, used_indices)\n\u001b[0;32m   1813\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     \u001b[39m# create train\u001b[39;00m\n\u001b[1;32m-> 1815\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, label\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel,\n\u001b[0;32m   1816\u001b[0m                     weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, group\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroup,\n\u001b[0;32m   1817\u001b[0m                     init_score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_score, predictor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predictor,\n\u001b[0;32m   1818\u001b[0m                     silent\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msilent, feature_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_name,\n\u001b[0;32m   1819\u001b[0m                     categorical_feature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcategorical_feature, params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[0;32m   1820\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfree_raw_data:\n\u001b[0;32m   1821\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\lightgbm\\basic.py:1474\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1472\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpandas_categorical \u001b[39m=\u001b[39m reference\u001b[39m.\u001b[39mpandas_categorical\n\u001b[0;32m   1473\u001b[0m     categorical_feature \u001b[39m=\u001b[39m reference\u001b[39m.\u001b[39mcategorical_feature\n\u001b[1;32m-> 1474\u001b[0m data, feature_name, categorical_feature, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpandas_categorical \u001b[39m=\u001b[39m _data_from_pandas(data,\n\u001b[0;32m   1475\u001b[0m                                                                                      feature_name,\n\u001b[0;32m   1476\u001b[0m                                                                                      categorical_feature,\n\u001b[0;32m   1477\u001b[0m                                                                                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpandas_categorical)\n\u001b[0;32m   1478\u001b[0m label \u001b[39m=\u001b[39m _label_from_pandas(label)\n\u001b[0;32m   1480\u001b[0m \u001b[39m# process for args\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\lightgbm\\basic.py:597\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    593\u001b[0m     bad_index_cols_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(data\u001b[39m.\u001b[39mcolumns[bad_indices])\n\u001b[0;32m    594\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataFrame.dtypes for data must be int, float or bool.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    595\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mDid not expect the data types in the following fields: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    596\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mbad_index_cols_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 597\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mvalues\n\u001b[0;32m    598\u001b[0m \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mfloat32 \u001b[39mand\u001b[39;00m data\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mfloat64:\n\u001b[0;32m    599\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\pandas\\core\\frame.py:10883\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  10810\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m  10811\u001b[0m \u001b[39mReturn a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  10812\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10880\u001b[0m \u001b[39m       ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  10881\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m  10882\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[1;32m> 10883\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array()\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1589\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1587\u001b[0m             arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1588\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1589\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[0;32m   1590\u001b[0m     \u001b[39m# The underlying data was copied within _interleave\u001b[39;00m\n\u001b[0;32m   1591\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1628\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1625\u001b[0m \u001b[39melif\u001b[39;00m is_dtype_equal(dtype, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1626\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1628\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m   1630\u001b[0m itemmask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m   1632\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m na_value \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n\u001b[0;32m   1633\u001b[0m     \u001b[39m# much more performant than using to_numpy below\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.16 GiB for an array with shape (1982, 146370) and data type float64"
     ]
    }
   ],
   "source": [
    "# 0.9706864963896972 and fail\n",
    "# Fail not enought memory (2.16 GiB)\n",
    "lgb_classifier, n_scores = train_LGBMClassifier(dataset_dict=dataset_dict_over_SMOTE, data_set_path=data_set_path, \n",
    "                            scores=scores, score_path=score_path, \n",
    "                            features=\"ALL\",  add_data=\"SMOTE\",commentaire=\"Amount and Add data on train\", \n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = n_scores\n",
    "save_score(n_scores, score_path=score_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Green; padding: 7px;\" >\n",
    "\n",
    "### 4.2. Ajout de données avec Borderline-SMOTE2\n",
    "</div>\n",
    "\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[over_BorderlineSMOTE]\tINFO  (146370, 1982), (146370,)                          \n",
      "[over_BorderlineSMOTE]\tINFO  c:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\dataset\\train_complete_OVER_BorderlineSMOTE_encoded_hyper_light_2023_01_19.csv \u001b[6;30;42mSAVE\u001b[0m                          \n"
     ]
    }
   ],
   "source": [
    "dataset_over_BorderlineSMOTE = over_dataset_with_BorderlineSMOTE(X_train,y_train, data_set_path=data_set_train_file_name, \n",
    "                    target = target, verbose=verbose)\n",
    "\n",
    "X_train_over = dataset_over_BorderlineSMOTE.drop(target, axis=1)\n",
    "y_train_over = complete_y_cols(X_train_over, y_param=dataset_over_BorderlineSMOTE[target])\n",
    "\n",
    "dataset_dict_over_BorderlineSMOTE = deepcopy(dataset_dict)\n",
    "dataset_dict_over_BorderlineSMOTE['X_train'] = X_train_over\n",
    "dataset_dict_over_BorderlineSMOTE['y_train'] = y_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot_X.append(dataset_dict_over_BorderlineSMOTE[\"X_train\"])\n",
    "to_plot_y.append(dataset_dict_over_BorderlineSMOTE[\"y_train\"])\n",
    "titles.append(\"BorderlineSMOTE\")\n",
    "\n",
    "plot_scatters(Xs=to_plot_X, ys=to_plot_y,titles=titles,target=target, size=(20, 20), verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### M.4.2. LogisticRegression\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "model, n_scores = train_LogisticRegression(dataset_dict=dataset_dict_over_BorderlineSMOTE, data_set_path=data_set_path, \n",
    "                            scores=scores, score_path=score_path, \n",
    "                            features=\"ALL\", add_data=\"BorderlineSMOTE\",commentaire=\"Amount and Add data on train\", \n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = n_scores\n",
    "save_score(n_scores, score_path=score_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### M.4.3. LGBMClassifier\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "lgb_classifier, n_scores = train_LGBMClassifier(dataset_dict=dataset_dict_over_BorderlineSMOTE, data_set_path=data_set_path, \n",
    "                            scores=scores, score_path=score_path, \n",
    "                            features=\"ALL\",  add_data=\"BorderlineSMOTE\",commentaire=\"Amount and Add data on train\", \n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = n_scores\n",
    "save_score(n_scores, score_path=score_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Green; padding: 7px;\" >\n",
    "\n",
    "### 4.2. Ajout de données avec SVMSMOTE\n",
    "</div>\n",
    "\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_over_BorderlineSMOTE = over_dataset_with_BorderlineSMOTE(X_train,y_train, data_set_path=data_set_train_file_name, \n",
    "                    target = target, verbose=verbose)\n",
    "\n",
    "X_train_over = dataset_over_BorderlineSMOTE.drop(target, axis=1)\n",
    "y_train_over = complete_y_cols(X_train_over, y_param=dataset_over_BorderlineSMOTE[target])\n",
    "\n",
    "dataset_dict_over_BorderlineSMOTE = deepcopy(dataset_dict)\n",
    "dataset_dict_over_BorderlineSMOTE['X_train'] = X_train_over\n",
    "dataset_dict_over_BorderlineSMOTE['y_train'] = y_train_over"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Blue; padding: 15px;\" >\n",
    "\n",
    "## 5.Modèles Recherche du modèle le plus adapté\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Green; padding: 7px;\" >\n",
    "\n",
    "### M.2. Recherche manuelle\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/comparing-different-classification-machine-learning-models-for-an-imbalanced-dataset-fdae1af3677f\n",
    "\n",
    "Logistic Regression, K Nearest Neighbors, Gradient Boosting Classifier, Decision Tree, Random Forest, Neural Net."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Green; padding: 7px;\" >\n",
    "\n",
    "### M.2. Grid SearCV simple\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Green; padding: 7px;\" >\n",
    "\n",
    "### M.1. Théories avant réalisation\n",
    "</div>\n",
    "\n",
    "\n",
    "Sources : \n",
    "- https://blog.octo.com/donnees-desequilibrees-que-faire/\n",
    "\n",
    "Idées : \n",
    "- approche naïve de classification ?  LightGBM et un Stochastic Gradient Descent ?\n",
    "\n",
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### M.1.1. Choisir les bonnes métriques\n",
    "</div>\n",
    "\n",
    "Métriques : Choisir la métrique la plus pertinente d’un point de vue métier\n",
    "- <mark>accuracy</mark> non pertinente\n",
    "- Le <mark>rappel</mark> indique la capacité du modèle à prédire correctement tous les positifs et la précision indique la capacité du modèle à ne prédire que les positifs.\n",
    "- <mark>score F1</mark> : est très intéressant quand il existe un double enjeu et qu’on cherche à avoir à la fois un bon rappel et une bonne précision.  Il s’agit d’une moyenne des deux métriques\n",
    "- Le coefficient de corrélation de <mark>Matthews</mark> ou le <mark>MCC</mark> reste la meilleure métrique à utiliser : Concrètement, si on considère que la classe prédite et la classe réelle sont deux variables binaires, le MCC représente la corrélation entre ces deux variables. C’est une métrique qui est symétrique et insensible au déséquilibre de classes.\n",
    "\n",
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### M.1.2. Traitement des données\n",
    "</div>\n",
    "\n",
    "Techniques de traitement\n",
    "- Techniques se basant sur l’amélioration du jeu de données\n",
    "- Techniques se basant sur l’amélioration de la phase de modélisation \n",
    "\n",
    "\n",
    "Lorsque le dataset n’est pas assez grand, on peut sur-échantillonner les observations associées à la classe la moins prépondérante. On peut générer de nouveaux échantillons par répétition de façon aléatoire ou en s’appuyant sur des méthodes un peu plus sophistiquées comme SMOTE ou ADASYN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Blue; padding: 15px;\" >\n",
    "\n",
    "## Z.Annexe\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idées / Questions :\n",
    "- Ajouter une colonne montant total\n",
    "- Ajouter une colonne nombre total d'article ?\n",
    "- Une catégorie d'article est-elle envisageable ?\n",
    "- Regroupement par tranche de prix des articles ? des paniers ?\n",
    "- Est-ce que certains articles sont plus soumis aux fraudes que d'autres ?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Modèle|Add Data|Features|Params|Accuracy Score|pr_auc_score TEST perso|pr_auc_score TEST officiel|Commentaire|\n",
    "|------|--------|--------|------|--------------|-----------------------|--------------------------|-----------|\n",
    "|LogisticRegression||Items|penalty=\"l2\", fit_intercept=True,solver='liblinear'|0.985073822610195|0.014656751805151417|0,0168117941201828|Sans ajout de données|\n",
    "|LGBMClassifier||Items|boosting_type='goss', max_depth=5,learning_rate=0.1,n_estimators=1000,subsample=0.8,colsample_bytree=0.6|0.9862592951826705|0.09303255321981446|0,07855741945152836|Sans ajout de données|\n",
    "|LogisticRegression|RandomOverSampler|Items|penalty=\"l2\", fit_intercept=True,solver='liblinear'|0.7336084615594851|0.6572881928321739|0,03211346653991237|AVEC ajout de données sur tout le dataset|\n",
    "|LGBMClassifier|RandomOverSampler|Items|boosting_type='goss', max_depth=5,learning_rate=0.1,n_estimators=1000,subsample=0.8,colsample_bytree=0.6|0.9259886851239444|0.8798873204426053|0,06849072266219955|AVEC ajout de données sur tout le dataset|\n",
    "|LogisticRegression||ALL|penalty=\"l2\", fit_intercept=True,solver='liblinear'|0.9849660523763336|0.014656751805151417| |SANS ajout de données|\n",
    "|LGBMClassifier||ALL|boosting_type='goss', max_depth=5,learning_rate=0.1,n_estimators=1000,subsample=0.8,colsample_bytree=0.6|0.9861515249488091|0.09301333707479051| |SANS ajout de données|\n",
    "|LogisticRegression|RandomOverSampler|ALL|penalty=\"l2\", fit_intercept=True,solver='liblinear'|0.7267484763180191|0.6507125123342998| |AVEC ajout de données sur tout le dataset|\n",
    "|LGBMClassifier|RandomOverSampler|ALL|boosting_type='goss', max_depth=5,learning_rate=0.1,n_estimators=1000,subsample=0.8,colsample_bytree=0.6|0.9322200661400968|0.8881964612621873| |AVEC ajout de données sur tout le dataset|\n",
    "|LogisticRegression|RandomOverSampler|ALL|penalty=\"l2\", fit_intercept=True,solver='liblinear'|0.5651471063692208|0.026699804461301335| |AVEC ajout de données sur Train only|\n",
    "|LGBMClassifier|RandomOverSampler|ALL|boosting_type='goss', max_depth=5,learning_rate=0.1,n_estimators=1000,subsample=0.8,colsample_bytree=0.6|0.8935230089449294|0.060563220710355574| |AVEC ajout de données sur Train only|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9861515249488091\n",
      "0.09301333707479051\n"
     ]
    }
   ],
   "source": [
    "lgb_classifier = lgb.LGBMClassifier(boosting_type='goss',  \n",
    "                                    max_depth=5, \n",
    "                                    learning_rate=0.1,\n",
    "                                    n_estimators=1000, \n",
    "                                    subsample=0.8,  \n",
    "                                    colsample_bytree=0.6,\n",
    "                                   )\n",
    "classifier = lgb_classifier.fit(X_train, y_train, verbose=verbose) \n",
    "score_accuracy = classifier.score(X_test, y_test)\n",
    "print(score_accuracy)\n",
    "y_pred = classifier.predict(X_test)\n",
    "pr_auc_score_, y_t_c, y_p_c = evaluate(X_test=X_test, y_test=y_test, y_pred=y_pred, verbose=verbose)\n",
    "print(pr_auc_score_)\n",
    "\n",
    "y_pred_test = classifier.predict(test_origin)\n",
    "y_pred_test_complete = complete_y_cols(X_test=test_origin, y_param=y_pred_test)\n",
    "res_path = join(data_set_path, \"All_LGBMClassifier_\"+datetime.now().strftime('%Y-%m-%d-%H_%M')+\".csv\")\n",
    "y_pred_test_complete.to_csv(res_path)\n",
    "\n",
    "n_scores = add_score(scores_param=scores, modele=\"LGBMClassifier\", features=\"ALL\", add_data=np.nan, \n",
    "          params=\"boosting_type='goss', max_depth=5,learning_rate=0.1,n_estimators=1000.subsample=0.8,colsample_bytree=0.6\", \n",
    "          accuracy_score=score_accuracy, pr_auc_score_TEST_perso=pr_auc_score_,\n",
    "          commentaire=np.nan,\n",
    "          score_path=score_path.replace(\".csv\", f\"{datetime.now().strftime('%Y-%m-%d_%H-%M')}.csv\"),\n",
    "          verbose=verbose)\n",
    "n_scores.sort_values(by=['Modèle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>Nb_of_items</th>\n",
       "      <th>item_BED LINEN_nb</th>\n",
       "      <th>item_BED LINEN_cash</th>\n",
       "      <th>item_BATHROOM_nb</th>\n",
       "      <th>item_BATHROOM_cash</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_nb</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_cash</th>\n",
       "      <th>item_TOYS_nb</th>\n",
       "      <th>...</th>\n",
       "      <th>make_BLUEBELLA_cash</th>\n",
       "      <th>make_ROLSER_nb</th>\n",
       "      <th>make_ROLSER_cash</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_nb</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_cash</th>\n",
       "      <th>make_TEMPLE ISLAND_nb</th>\n",
       "      <th>make_TEMPLE ISLAND_cash</th>\n",
       "      <th>make_GHD_nb</th>\n",
       "      <th>make_GHD_cash</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12214</td>\n",
       "      <td>79535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21619</td>\n",
       "      <td>56408</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1635.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18886</td>\n",
       "      <td>14674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85690</td>\n",
       "      <td>33513</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30417</td>\n",
       "      <td>65918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74227</th>\n",
       "      <td>6265</td>\n",
       "      <td>5177</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74228</th>\n",
       "      <td>54886</td>\n",
       "      <td>77904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74229</th>\n",
       "      <td>76820</td>\n",
       "      <td>83123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74230</th>\n",
       "      <td>860</td>\n",
       "      <td>52208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74231</th>\n",
       "      <td>15795</td>\n",
       "      <td>69952</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2598.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74232 rows × 1982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     ID  Nb_of_items  item_BED LINEN_nb  item_BED LINEN_cash  \\\n",
       "0      12214  79535          1.0                0.0                  0.0   \n",
       "1      21619  56408          3.0                0.0                  0.0   \n",
       "2      18886  14674          1.0                0.0                  0.0   \n",
       "3      85690  33513          3.0                0.0                  0.0   \n",
       "4      30417  65918          1.0                0.0                  0.0   \n",
       "...      ...    ...          ...                ...                  ...   \n",
       "74227   6265   5177          3.0                0.0                  0.0   \n",
       "74228  54886  77904          1.0                0.0                  0.0   \n",
       "74229  76820  83123          1.0                0.0                  0.0   \n",
       "74230    860  52208          1.0                0.0                  0.0   \n",
       "74231  15795  69952          2.0                0.0                  0.0   \n",
       "\n",
       "       item_BATHROOM_nb  item_BATHROOM_cash  \\\n",
       "0                   0.0                 0.0   \n",
       "1                   0.0                 0.0   \n",
       "2                   0.0                 0.0   \n",
       "3                   0.0                 0.0   \n",
       "4                   0.0                 0.0   \n",
       "...                 ...                 ...   \n",
       "74227               0.0                 0.0   \n",
       "74228               0.0                 0.0   \n",
       "74229               0.0                 0.0   \n",
       "74230               0.0                 0.0   \n",
       "74231               0.0                 0.0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_nb  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "74227                                   0.0   \n",
       "74228                                   0.0   \n",
       "74229                                   0.0   \n",
       "74230                                   0.0   \n",
       "74231                                   0.0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_cash  item_TOYS_nb  ...  \\\n",
       "0                                         0.0           0.0  ...   \n",
       "1                                         0.0           0.0  ...   \n",
       "2                                         0.0           0.0  ...   \n",
       "3                                         0.0           0.0  ...   \n",
       "4                                         0.0           0.0  ...   \n",
       "...                                       ...           ...  ...   \n",
       "74227                                     0.0           0.0  ...   \n",
       "74228                                     0.0           0.0  ...   \n",
       "74229                                     0.0           0.0  ...   \n",
       "74230                                     0.0           0.0  ...   \n",
       "74231                                     0.0           0.0  ...   \n",
       "\n",
       "       make_BLUEBELLA_cash  make_ROLSER_nb  make_ROLSER_cash  \\\n",
       "0                      0.0             0.0               0.0   \n",
       "1                      0.0             0.0               0.0   \n",
       "2                      0.0             0.0               0.0   \n",
       "3                      0.0             0.0               0.0   \n",
       "4                      0.0             0.0               0.0   \n",
       "...                    ...             ...               ...   \n",
       "74227                  0.0             0.0               0.0   \n",
       "74228                  0.0             0.0               0.0   \n",
       "74229                  0.0             0.0               0.0   \n",
       "74230                  0.0             0.0               0.0   \n",
       "74231                  0.0             0.0               0.0   \n",
       "\n",
       "       make_DARTINGTON CRYSTAL_nb  make_DARTINGTON CRYSTAL_cash  \\\n",
       "0                             0.0                           0.0   \n",
       "1                             0.0                           0.0   \n",
       "2                             0.0                           0.0   \n",
       "3                             0.0                           0.0   \n",
       "4                             0.0                           0.0   \n",
       "...                           ...                           ...   \n",
       "74227                         0.0                           0.0   \n",
       "74228                         0.0                           0.0   \n",
       "74229                         0.0                           0.0   \n",
       "74230                         0.0                           0.0   \n",
       "74231                         0.0                           0.0   \n",
       "\n",
       "       make_TEMPLE ISLAND_nb  make_TEMPLE ISLAND_cash  make_GHD_nb  \\\n",
       "0                        0.0                      0.0          0.0   \n",
       "1                        0.0                      0.0          0.0   \n",
       "2                        0.0                      0.0          0.0   \n",
       "3                        0.0                      0.0          0.0   \n",
       "4                        0.0                      0.0          0.0   \n",
       "...                      ...                      ...          ...   \n",
       "74227                    0.0                      0.0          0.0   \n",
       "74228                    0.0                      0.0          0.0   \n",
       "74229                    0.0                      0.0          0.0   \n",
       "74230                    0.0                      0.0          0.0   \n",
       "74231                    0.0                      0.0          0.0   \n",
       "\n",
       "       make_GHD_cash  amount  \n",
       "0                0.0  1197.0  \n",
       "1                0.0  1635.0  \n",
       "2                0.0  2639.0  \n",
       "3                0.0  1873.0  \n",
       "4                0.0  1249.0  \n",
       "...              ...     ...  \n",
       "74227            0.0   900.0  \n",
       "74228            0.0  1699.0  \n",
       "74229            0.0   369.0  \n",
       "74230            0.0  1407.0  \n",
       "74231            0.0  2598.0  \n",
       "\n",
       "[74232 rows x 1982 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = add_amounts(X_train, verbose=verbose)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>Nb_of_items</th>\n",
       "      <th>item_BED LINEN_nb</th>\n",
       "      <th>item_BED LINEN_cash</th>\n",
       "      <th>item_BATHROOM_nb</th>\n",
       "      <th>item_BATHROOM_cash</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_nb</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_cash</th>\n",
       "      <th>item_TOYS_nb</th>\n",
       "      <th>...</th>\n",
       "      <th>make_BLUEBELLA_cash</th>\n",
       "      <th>make_ROLSER_nb</th>\n",
       "      <th>make_ROLSER_cash</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_nb</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_cash</th>\n",
       "      <th>make_TEMPLE ISLAND_nb</th>\n",
       "      <th>make_TEMPLE ISLAND_cash</th>\n",
       "      <th>make_GHD_nb</th>\n",
       "      <th>make_GHD_cash</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46180</td>\n",
       "      <td>107424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25031</td>\n",
       "      <td>74645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32798</td>\n",
       "      <td>102653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38656</td>\n",
       "      <td>23831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16271</td>\n",
       "      <td>60691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18553</th>\n",
       "      <td>14569</td>\n",
       "      <td>96137</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18554</th>\n",
       "      <td>70048</td>\n",
       "      <td>84464</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18555</th>\n",
       "      <td>39431</td>\n",
       "      <td>62549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2849.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18556</th>\n",
       "      <td>34291</td>\n",
       "      <td>89894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18557</th>\n",
       "      <td>35360</td>\n",
       "      <td>64654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1599.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18558 rows × 1982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index      ID  Nb_of_items  item_BED LINEN_nb  item_BED LINEN_cash  \\\n",
       "0      46180  107424          1.0                0.0                  0.0   \n",
       "1      25031   74645          1.0                0.0                  0.0   \n",
       "2      32798  102653          1.0                0.0                  0.0   \n",
       "3      38656   23831          1.0                0.0                  0.0   \n",
       "4      16271   60691          1.0                0.0                  0.0   \n",
       "...      ...     ...          ...                ...                  ...   \n",
       "18553  14569   96137          2.0                0.0                  0.0   \n",
       "18554  70048   84464          2.0                0.0                  0.0   \n",
       "18555  39431   62549          1.0                0.0                  0.0   \n",
       "18556  34291   89894          1.0                0.0                  0.0   \n",
       "18557  35360   64654          1.0                0.0                  0.0   \n",
       "\n",
       "       item_BATHROOM_nb  item_BATHROOM_cash  \\\n",
       "0                   0.0                 0.0   \n",
       "1                   0.0                 0.0   \n",
       "2                   0.0                 0.0   \n",
       "3                   0.0                 0.0   \n",
       "4                   0.0                 0.0   \n",
       "...                 ...                 ...   \n",
       "18553               0.0                 0.0   \n",
       "18554               0.0                 0.0   \n",
       "18555               0.0                 0.0   \n",
       "18556               0.0                 0.0   \n",
       "18557               0.0                 0.0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_nb  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "18553                                   0.0   \n",
       "18554                                   0.0   \n",
       "18555                                   0.0   \n",
       "18556                                   0.0   \n",
       "18557                                   0.0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_cash  item_TOYS_nb  ...  \\\n",
       "0                                         0.0           0.0  ...   \n",
       "1                                         0.0           0.0  ...   \n",
       "2                                         0.0           0.0  ...   \n",
       "3                                         0.0           0.0  ...   \n",
       "4                                         0.0           0.0  ...   \n",
       "...                                       ...           ...  ...   \n",
       "18553                                     0.0           0.0  ...   \n",
       "18554                                     0.0           0.0  ...   \n",
       "18555                                     0.0           0.0  ...   \n",
       "18556                                     0.0           0.0  ...   \n",
       "18557                                     0.0           0.0  ...   \n",
       "\n",
       "       make_BLUEBELLA_cash  make_ROLSER_nb  make_ROLSER_cash  \\\n",
       "0                      0.0             0.0               0.0   \n",
       "1                      0.0             0.0               0.0   \n",
       "2                      0.0             0.0               0.0   \n",
       "3                      0.0             0.0               0.0   \n",
       "4                      0.0             0.0               0.0   \n",
       "...                    ...             ...               ...   \n",
       "18553                  0.0             0.0               0.0   \n",
       "18554                  0.0             0.0               0.0   \n",
       "18555                  0.0             0.0               0.0   \n",
       "18556                  0.0             0.0               0.0   \n",
       "18557                  0.0             0.0               0.0   \n",
       "\n",
       "       make_DARTINGTON CRYSTAL_nb  make_DARTINGTON CRYSTAL_cash  \\\n",
       "0                             0.0                           0.0   \n",
       "1                             0.0                           0.0   \n",
       "2                             0.0                           0.0   \n",
       "3                             0.0                           0.0   \n",
       "4                             0.0                           0.0   \n",
       "...                           ...                           ...   \n",
       "18553                         0.0                           0.0   \n",
       "18554                         0.0                           0.0   \n",
       "18555                         0.0                           0.0   \n",
       "18556                         0.0                           0.0   \n",
       "18557                         0.0                           0.0   \n",
       "\n",
       "       make_TEMPLE ISLAND_nb  make_TEMPLE ISLAND_cash  make_GHD_nb  \\\n",
       "0                        0.0                      0.0          0.0   \n",
       "1                        0.0                      0.0          0.0   \n",
       "2                        0.0                      0.0          0.0   \n",
       "3                        0.0                      0.0          0.0   \n",
       "4                        0.0                      0.0          0.0   \n",
       "...                      ...                      ...          ...   \n",
       "18553                    0.0                      0.0          0.0   \n",
       "18554                    0.0                      0.0          0.0   \n",
       "18555                    0.0                      0.0          0.0   \n",
       "18556                    0.0                      0.0          0.0   \n",
       "18557                    0.0                      0.0          0.0   \n",
       "\n",
       "       make_GHD_cash  amount  \n",
       "0                0.0   499.0  \n",
       "1                0.0  1100.0  \n",
       "2                0.0  1187.0  \n",
       "3                0.0   479.0  \n",
       "4                0.0  1199.0  \n",
       "...              ...     ...  \n",
       "18553            0.0  2610.0  \n",
       "18554            0.0  1419.0  \n",
       "18555            0.0  2849.0  \n",
       "18556            0.0  2499.0  \n",
       "18557            0.0  1599.0  \n",
       "\n",
       "[18558 rows x 1982 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = add_amounts(X_test, verbose=verbose)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>Nb_of_items</th>\n",
       "      <th>item_BED LINEN_nb</th>\n",
       "      <th>item_BED LINEN_cash</th>\n",
       "      <th>item_BATHROOM_nb</th>\n",
       "      <th>item_BATHROOM_cash</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_nb</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_cash</th>\n",
       "      <th>item_TOYS_nb</th>\n",
       "      <th>...</th>\n",
       "      <th>make_BLUEBELLA_cash</th>\n",
       "      <th>make_ROLSER_nb</th>\n",
       "      <th>make_ROLSER_cash</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_nb</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_cash</th>\n",
       "      <th>make_TEMPLE ISLAND_nb</th>\n",
       "      <th>make_TEMPLE ISLAND_cash</th>\n",
       "      <th>make_GHD_nb</th>\n",
       "      <th>make_GHD_cash</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>85517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>51113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>83008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>78712</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>77846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92785</th>\n",
       "      <td>0</td>\n",
       "      <td>21243</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92786</th>\n",
       "      <td>0</td>\n",
       "      <td>45891</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92787</th>\n",
       "      <td>0</td>\n",
       "      <td>42613</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1727.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92788</th>\n",
       "      <td>0</td>\n",
       "      <td>43567</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92789</th>\n",
       "      <td>0</td>\n",
       "      <td>68268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>799.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92790 rows × 1982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     ID  Nb_of_items  item_BED LINEN_nb  item_BED LINEN_cash  \\\n",
       "index                                                                      \n",
       "0          0  85517          1.0                0.0                  0.0   \n",
       "1          0  51113          1.0                0.0                  0.0   \n",
       "2          0  83008          1.0                0.0                  0.0   \n",
       "3          0  78712          2.0                0.0                  0.0   \n",
       "4          0  77846          1.0                0.0                  0.0   \n",
       "...      ...    ...          ...                ...                  ...   \n",
       "92785      0  21243          2.0                0.0                  0.0   \n",
       "92786      0  45891          1.0                0.0                  0.0   \n",
       "92787      0  42613          3.0                0.0                  0.0   \n",
       "92788      0  43567          2.0                0.0                  0.0   \n",
       "92789      0  68268          1.0                0.0                  0.0   \n",
       "\n",
       "       item_BATHROOM_nb  item_BATHROOM_cash  \\\n",
       "index                                         \n",
       "0                   0.0                 0.0   \n",
       "1                   0.0                 0.0   \n",
       "2                   0.0                 0.0   \n",
       "3                   0.0                 0.0   \n",
       "4                   0.0                 0.0   \n",
       "...                 ...                 ...   \n",
       "92785               0.0                 0.0   \n",
       "92786               0.0                 0.0   \n",
       "92787               0.0                 0.0   \n",
       "92788               0.0                 0.0   \n",
       "92789               0.0                 0.0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_nb  \\\n",
       "index                                         \n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "92785                                   0.0   \n",
       "92786                                   0.0   \n",
       "92787                                   0.0   \n",
       "92788                                   0.0   \n",
       "92789                                   0.0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_cash  item_TOYS_nb  ...  \\\n",
       "index                                                        ...   \n",
       "0                                         0.0           0.0  ...   \n",
       "1                                         0.0           0.0  ...   \n",
       "2                                         0.0           0.0  ...   \n",
       "3                                         0.0           0.0  ...   \n",
       "4                                         0.0           0.0  ...   \n",
       "...                                       ...           ...  ...   \n",
       "92785                                     0.0           0.0  ...   \n",
       "92786                                     0.0           0.0  ...   \n",
       "92787                                     0.0           0.0  ...   \n",
       "92788                                     0.0           0.0  ...   \n",
       "92789                                     0.0           0.0  ...   \n",
       "\n",
       "       make_BLUEBELLA_cash  make_ROLSER_nb  make_ROLSER_cash  \\\n",
       "index                                                          \n",
       "0                      0.0             0.0               0.0   \n",
       "1                      0.0             0.0               0.0   \n",
       "2                      0.0             0.0               0.0   \n",
       "3                      0.0             0.0               0.0   \n",
       "4                      0.0             0.0               0.0   \n",
       "...                    ...             ...               ...   \n",
       "92785                  0.0             0.0               0.0   \n",
       "92786                  0.0             0.0               0.0   \n",
       "92787                  0.0             0.0               0.0   \n",
       "92788                  0.0             0.0               0.0   \n",
       "92789                  0.0             0.0               0.0   \n",
       "\n",
       "       make_DARTINGTON CRYSTAL_nb  make_DARTINGTON CRYSTAL_cash  \\\n",
       "index                                                             \n",
       "0                             0.0                           0.0   \n",
       "1                             0.0                           0.0   \n",
       "2                             0.0                           0.0   \n",
       "3                             0.0                           0.0   \n",
       "4                             0.0                           0.0   \n",
       "...                           ...                           ...   \n",
       "92785                         0.0                           0.0   \n",
       "92786                         0.0                           0.0   \n",
       "92787                         0.0                           0.0   \n",
       "92788                         0.0                           0.0   \n",
       "92789                         0.0                           0.0   \n",
       "\n",
       "       make_TEMPLE ISLAND_nb  make_TEMPLE ISLAND_cash  make_GHD_nb  \\\n",
       "index                                                                \n",
       "0                        0.0                      0.0          0.0   \n",
       "1                        0.0                      0.0          0.0   \n",
       "2                        0.0                      0.0          0.0   \n",
       "3                        0.0                      0.0          0.0   \n",
       "4                        0.0                      0.0          0.0   \n",
       "...                      ...                      ...          ...   \n",
       "92785                    0.0                      0.0          0.0   \n",
       "92786                    0.0                      0.0          0.0   \n",
       "92787                    0.0                      0.0          0.0   \n",
       "92788                    0.0                      0.0          0.0   \n",
       "92789                    0.0                      0.0          0.0   \n",
       "\n",
       "       make_GHD_cash  amount  \n",
       "index                         \n",
       "0                0.0   889.0  \n",
       "1                0.0   409.0  \n",
       "2                0.0  1399.0  \n",
       "3                0.0   808.0  \n",
       "4                0.0  1199.0  \n",
       "...              ...     ...  \n",
       "92785            0.0   306.0  \n",
       "92786            0.0   898.0  \n",
       "92787            0.0  1727.0  \n",
       "92788            0.0  3198.0  \n",
       "92789            0.0   799.0  \n",
       "\n",
       "[92790 rows x 1982 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_origin = add_amounts(test_origin, verbose=verbose)\n",
    "test_origin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa1a338178f9f930bee8bd77ef02489fdd5066fc93282fb64038484aff075692"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
