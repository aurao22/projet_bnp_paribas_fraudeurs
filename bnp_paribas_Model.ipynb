{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: RGB(255,114,0);\" >\n",
    "<div>\n",
    "<img src=\"img/fraudeur_-_BNPP_PF_-_finale.jpg\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "# PROJET - Comment démasquer les fraudeurs ? <mark>EDA toutes les données</mark>\n",
    "</div>\n",
    "\n",
    "par BNP Paribas PF\n",
    "\n",
    "Lien vers le challenge : https://challengedata.ens.fr/participants/challenges/104/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Blue; padding: 15px;\" >\n",
    "\n",
    "## 1.CHARGEMENT des données\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current execution path : c:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\n",
      "Dataset path : c:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\dataset\n"
     ]
    }
   ],
   "source": [
    "from os import getcwd\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pr_auc_score_SB05ixL import *\n",
    "from bnp_paribas import *\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "#                               MAIN\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "verbose = 1\n",
    "\n",
    "target = \"fraud_flag\"\n",
    "\n",
    "# Récupère le répertoire du programme\n",
    "execution_path = getcwd().split(\"projet_bnp_paribas_fraudeurs\")[0]\n",
    "execution_path = join(execution_path, 'projet_bnp_paribas_fraudeurs')\n",
    "\n",
    "model_path = join(execution_path, 'model')\n",
    "\n",
    "data_set_path = join(execution_path, 'dataset')\n",
    "train_file_name = \"train_complete_encoded_hyper_light_2023_01_19.csv\"\n",
    "data_set_train_file_name = join(data_set_path, train_file_name)\n",
    "\n",
    "print(f\"Current execution path : {execution_path}\")\n",
    "print(f\"Dataset path : {data_set_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Chargement des données pré-traitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_splited_data   ]\tINFO  \u001b[6;30;42mIN PROGRESS...\u001b[0m                          \n",
      "[load_splited_data   ]\tINFO  over BorderlineSMOTE Loading X_train...                          \n",
      "[load_over_dataset   ]\tINFO  (146370, 1982) datas \u001b[6;30;42mLOAD\u001b[0m                          \n",
      "[load_splited_data   ]\tINFO  set X_test Loading X_test...                          \n",
      "[reduce_data_by_typing]\tINFO  ID                           int64\n",
      "Nb_of_items                float64\n",
      "item_BED LINEN_nb          float64\n",
      "item_BED LINEN_cash        float64\n",
      "item_BATHROOM_nb           float64\n",
      "                            ...   \n",
      "make_TEMPLE ISLAND_nb      float64\n",
      "make_TEMPLE ISLAND_cash    float64\n",
      "make_GHD_nb                float64\n",
      "make_GHD_cash              float64\n",
      "amount                     float64\n",
      "Length: 1981, dtype: object                          \n",
      "[reduce_data_by_typing]\tINFO  ID                           int64\n",
      "Nb_of_items                   int8\n",
      "item_BED LINEN_nb             int8\n",
      "item_BED LINEN_cash        float16\n",
      "item_BATHROOM_nb              int8\n",
      "                            ...   \n",
      "make_TEMPLE ISLAND_nb         int8\n",
      "make_TEMPLE ISLAND_cash    float16\n",
      "make_GHD_nb                   int8\n",
      "make_GHD_cash              float16\n",
      "amount                     float16\n",
      "Length: 1981, dtype: object                          \n",
      "[load_splited_data   ]\tINFO  set y_test Loading y_test...                          \n",
      "[load_splited_data   ]\tINFO  4 dataset \u001b[6;30;42mLOAD\u001b[0m                          \n",
      "[load_splited_data   ]\tINFO  (146370, 1981) / (18558, 1981)                          \n"
     ]
    }
   ],
   "source": [
    "# [load_splited_data   ]\tINFO  Chargement des données train sources...                          \n",
    "# [load_splited_data   ]\tINFO  (92790, 1981) train données chargées                          \n",
    "# [load_splited_data   ]\tINFO  Séparation de X et y...                          \n",
    "# [load_splited_data   ]\tINFO  split du dataset_path...                          \n",
    "# [load_splited_data   ]\tINFO  5 dataset LOAD                          \n",
    "# [load_splited_data   ]\tINFO  (74232, 1980) / (18558, 1980) \n",
    "over_name=\"BorderlineSMOTE\"\n",
    "random_state = 42\n",
    "dataset_dict = load_splited_data(dataset_path=data_set_train_file_name,over_name=over_name, random_state = random_state, save_it=True, force=False, verbose=verbose)\n",
    "\n",
    "X_train, X_test, y_train, y_test, train_origin = dataset_dict.get(\"X_train\", None), dataset_dict.get(\"X_test\", None), dataset_dict.get(\"y_train\", None), dataset_dict.get(\"y_test\", None), dataset_dict.get(\"train_origin\", None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Chargement du set de test officiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\WORK\\\\workspace-ia\\\\PROJETS\\\\projet_bnp_paribas_fraudeurs\\\\dataset\\\\train_complete_encoded_hyper_light_2023_01_19.csv'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_train_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\WORK\\\\workspace-ia\\\\PROJETS\\\\projet_bnp_paribas_fraudeurs\\\\dataset\\\\test_complete_encoded_hyper_light_2023_01_19.csv'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_test_file_name = data_set_train_file_name.replace(\"train_\", \"test_\")\n",
    "print(exists(data_set_test_file_name))\n",
    "data_set_test_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reduce_data_by_typing]\tINFO  ID                           int64\n",
      "Nb_of_items                  int64\n",
      "item_BED LINEN_nb            int64\n",
      "item_BED LINEN_cash        float64\n",
      "item_BATHROOM_nb             int64\n",
      "                            ...   \n",
      "make_TEMPLE ISLAND_nb        int64\n",
      "make_TEMPLE ISLAND_cash    float64\n",
      "make_GHD_nb                  int64\n",
      "make_GHD_cash              float64\n",
      "amount                     float64\n",
      "Length: 1981, dtype: object                          \n",
      "[reduce_data_by_typing]\tINFO  ID                           int64\n",
      "Nb_of_items                   int8\n",
      "item_BED LINEN_nb             int8\n",
      "item_BED LINEN_cash        float16\n",
      "item_BATHROOM_nb              int8\n",
      "                            ...   \n",
      "make_TEMPLE ISLAND_nb         int8\n",
      "make_TEMPLE ISLAND_cash    float16\n",
      "make_GHD_nb                   int8\n",
      "make_GHD_cash              float16\n",
      "amount                     float16\n",
      "Length: 1981, dtype: object                          \n",
      "[load_test_df        ]\tINFO  (23198, 1981) test données mises à jour                          \n",
      "[load_test_df        ]\tINFO  (23198, 1981) test données chargées                          \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Nb_of_items</th>\n",
       "      <th>item_BED LINEN_nb</th>\n",
       "      <th>item_BED LINEN_cash</th>\n",
       "      <th>item_BATHROOM_nb</th>\n",
       "      <th>item_BATHROOM_cash</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_nb</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_cash</th>\n",
       "      <th>item_TOYS_nb</th>\n",
       "      <th>item_TOYS_cash</th>\n",
       "      <th>...</th>\n",
       "      <th>make_BLUEBELLA_cash</th>\n",
       "      <th>make_ROLSER_nb</th>\n",
       "      <th>make_ROLSER_cash</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_nb</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_cash</th>\n",
       "      <th>make_TEMPLE ISLAND_nb</th>\n",
       "      <th>make_TEMPLE ISLAND_cash</th>\n",
       "      <th>make_GHD_nb</th>\n",
       "      <th>make_GHD_cash</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64707</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63919</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15664</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>929.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6626</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26766</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23193</th>\n",
       "      <td>63474</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23194</th>\n",
       "      <td>80438</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23195</th>\n",
       "      <td>29485</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23196</th>\n",
       "      <td>59838</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23197</th>\n",
       "      <td>110584</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1776.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23198 rows × 1981 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  Nb_of_items  item_BED LINEN_nb  item_BED LINEN_cash  \\\n",
       "index                                                                \n",
       "0       64707            1                  0                  0.0   \n",
       "1       63919            1                  0                  0.0   \n",
       "2       15664            1                  0                  0.0   \n",
       "3        6626            2                  0                  0.0   \n",
       "4       26766            1                  0                  0.0   \n",
       "...       ...          ...                ...                  ...   \n",
       "23193   63474            2                  0                  0.0   \n",
       "23194   80438            1                  0                  0.0   \n",
       "23195   29485            1                  0                  0.0   \n",
       "23196   59838            2                  0                  0.0   \n",
       "23197  110584            2                  0                  0.0   \n",
       "\n",
       "       item_BATHROOM_nb  item_BATHROOM_cash  \\\n",
       "index                                         \n",
       "0                     0                   0   \n",
       "1                     0                   0   \n",
       "2                     0                   0   \n",
       "3                     0                   0   \n",
       "4                     0                   0   \n",
       "...                 ...                 ...   \n",
       "23193                 0                   0   \n",
       "23194                 0                   0   \n",
       "23195                 0                   0   \n",
       "23196                 0                   0   \n",
       "23197                 0                   0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_nb  \\\n",
       "index                                         \n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "...                                     ...   \n",
       "23193                                     0   \n",
       "23194                                     0   \n",
       "23195                                     0   \n",
       "23196                                     0   \n",
       "23197                                     0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_cash  item_TOYS_nb  item_TOYS_cash  \\\n",
       "index                                                                         \n",
       "0                                         0.0             0             0.0   \n",
       "1                                         0.0             0             0.0   \n",
       "2                                         0.0             0             0.0   \n",
       "3                                         0.0             0             0.0   \n",
       "4                                         0.0             0             0.0   \n",
       "...                                       ...           ...             ...   \n",
       "23193                                     0.0             0             0.0   \n",
       "23194                                     0.0             0             0.0   \n",
       "23195                                     0.0             0             0.0   \n",
       "23196                                     0.0             0             0.0   \n",
       "23197                                     0.0             0             0.0   \n",
       "\n",
       "       ...  make_BLUEBELLA_cash  make_ROLSER_nb  make_ROLSER_cash  \\\n",
       "index  ...                                                          \n",
       "0      ...                    0               0                 0   \n",
       "1      ...                    0               0                 0   \n",
       "2      ...                    0               0                 0   \n",
       "3      ...                    0               0                 0   \n",
       "4      ...                    0               0                 0   \n",
       "...    ...                  ...             ...               ...   \n",
       "23193  ...                    0               0                 0   \n",
       "23194  ...                    0               0                 0   \n",
       "23195  ...                    0               0                 0   \n",
       "23196  ...                    0               0                 0   \n",
       "23197  ...                    0               0                 0   \n",
       "\n",
       "       make_DARTINGTON CRYSTAL_nb  make_DARTINGTON CRYSTAL_cash  \\\n",
       "index                                                             \n",
       "0                               0                           0.0   \n",
       "1                               0                           0.0   \n",
       "2                               0                           0.0   \n",
       "3                               0                           0.0   \n",
       "4                               0                           0.0   \n",
       "...                           ...                           ...   \n",
       "23193                           0                           0.0   \n",
       "23194                           0                           0.0   \n",
       "23195                           0                           0.0   \n",
       "23196                           0                           0.0   \n",
       "23197                           0                           0.0   \n",
       "\n",
       "       make_TEMPLE ISLAND_nb  make_TEMPLE ISLAND_cash  make_GHD_nb  \\\n",
       "index                                                                \n",
       "0                          0                      0.0            0   \n",
       "1                          0                      0.0            0   \n",
       "2                          0                      0.0            0   \n",
       "3                          0                      0.0            0   \n",
       "4                          0                      0.0            0   \n",
       "...                      ...                      ...          ...   \n",
       "23193                      0                      0.0            0   \n",
       "23194                      0                      0.0            0   \n",
       "23195                      0                      0.0            0   \n",
       "23196                      0                      0.0            0   \n",
       "23197                      0                      0.0            0   \n",
       "\n",
       "       make_GHD_cash  amount  \n",
       "index                         \n",
       "0                0.0   399.0  \n",
       "1                0.0   294.0  \n",
       "2                0.0   929.0  \n",
       "3                0.0   546.0  \n",
       "4                0.0  2470.0  \n",
       "...              ...     ...  \n",
       "23193            0.0   516.0  \n",
       "23194            0.0  1189.0  \n",
       "23195            0.0  1649.0  \n",
       "23196            0.0   409.0  \n",
       "23197            0.0  1776.0  \n",
       "\n",
       "[23198 rows x 1981 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file_name= \"test_complete_encoded_2023_01_19.csv\"\n",
    "data_set_test_file_name = data_set_train_file_name.replace(\"train_\", \"test_\")\n",
    "test_origin = load_test_df(file_path=data_set_test_file_name, train_columns=X_train.columns, verbose=verbose)\n",
    "dataset_dict[\"test_origin\"] = test_origin\n",
    "test_origin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Chargement des scores déjà enregistrés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>Features</th>\n",
       "      <th>Add Data</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>pr_auc_score TEST perso</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>pr_auc_score TEST officiel</th>\n",
       "      <th>Params</th>\n",
       "      <th>Commentaire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-02-15 16:37</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>BorderlineSMOTE</td>\n",
       "      <td>0.974458</td>\n",
       "      <td>0.069366</td>\n",
       "      <td>0.192252</td>\n",
       "      <td>0.168098</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>over data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-15 16:39</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>BorderlineSMOTE</td>\n",
       "      <td>0.728473</td>\n",
       "      <td>0.030205</td>\n",
       "      <td>0.059238</td>\n",
       "      <td>0.078557</td>\n",
       "      <td>random_state=42,max_depth=2,n_estimators=1000</td>\n",
       "      <td>over data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-20 16:16</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>Items</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.986259</td>\n",
       "      <td>0.093033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078557</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>Sans ajout de données</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-21 17:29</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>Items</td>\n",
       "      <td>RandomOverSampler amount less</td>\n",
       "      <td>0.925989</td>\n",
       "      <td>0.879887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068491</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>AVEC ajout de données sur tout le dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-21 17:31</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Items</td>\n",
       "      <td>RandomOverSampler amount less</td>\n",
       "      <td>0.733608</td>\n",
       "      <td>0.657288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032113</td>\n",
       "      <td>penalty=\"l2\", fit_intercept=True,solver='libli...</td>\n",
       "      <td>AVEC ajout de données sur tout le dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-20 15:29</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Items</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985074</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>penalty=\"l2\", fit_intercept=True,solver='libli...</td>\n",
       "      <td>Sans ajout de données</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-15 16:36</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>BorderlineSMOTE</td>\n",
       "      <td>0.561645</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>0.053348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty='l2', fit_intercept=True,solver='libli...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-21 17:45</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler amount less</td>\n",
       "      <td>0.932220</td>\n",
       "      <td>0.888196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>AVEC ajout de données sur tout le dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-21 17:40</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler amount less</td>\n",
       "      <td>0.726748</td>\n",
       "      <td>0.650713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty=\"l2\", fit_intercept=True,solver='libli...</td>\n",
       "      <td>AVEC ajout de données sur tout le dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-21 17:35</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.986152</td>\n",
       "      <td>0.093013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>SANS ajout de données</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 14:59</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985936</td>\n",
       "      <td>0.078879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 16:56</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985667</td>\n",
       "      <td>0.070795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>add amount column</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-15 15:46</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>BorderlineSMOTE</td>\n",
       "      <td>0.974458</td>\n",
       "      <td>0.069366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>over data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 17:04</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.931674</td>\n",
       "      <td>0.068321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>Add amount and Add data on train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 17:53</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>BorderlineSMOTE</td>\n",
       "      <td>0.980440</td>\n",
       "      <td>0.065619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>Amount and Add data on train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-13 11:00</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler amount less</td>\n",
       "      <td>0.893523</td>\n",
       "      <td>0.060563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>AVEC ajout de données sur Train only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 15:45</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler amount less</td>\n",
       "      <td>0.928387</td>\n",
       "      <td>0.059118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>boosting_type='goss', max_depth=5,learning_rat...</td>\n",
       "      <td>Add data on train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-15 15:48</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>ALL</td>\n",
       "      <td>BorderlineSMOTE</td>\n",
       "      <td>0.728473</td>\n",
       "      <td>0.030205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>random_state=42,max_depth=2,n_estimators=1000</td>\n",
       "      <td>over data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 17:52</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>BorderlineSMOTE</td>\n",
       "      <td>0.634336</td>\n",
       "      <td>0.028390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty='l2', fit_intercept=True,solver='libli...</td>\n",
       "      <td>Amount and Add data on train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 15:42</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.606261</td>\n",
       "      <td>0.026763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty='l2', fit_intercept=True,solver='libli...</td>\n",
       "      <td>Add data on train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-13 10:00</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler amount less</td>\n",
       "      <td>0.565147</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty=\"l2\", fit_intercept=True,solver='libli...</td>\n",
       "      <td>AVEC ajout de données sur Train only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-15 15:44</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>BorderlineSMOTE</td>\n",
       "      <td>0.561645</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty='l2', fit_intercept=True,solver='libli...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 17:03</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>0.598610</td>\n",
       "      <td>0.026163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty='l2', fit_intercept=True,solver='libli...</td>\n",
       "      <td>Add amount and Add data on train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 10:55</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>SMOTE_minority amount less</td>\n",
       "      <td>0.545425</td>\n",
       "      <td>0.025792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty=l2, fit_intercept=True,solver='liblinear'</td>\n",
       "      <td>Add data on Train on minority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-21 17:30</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.984966</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty=\"l2\", fit_intercept=True,solver='libli...</td>\n",
       "      <td>SANS ajout de données</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 16:52</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.984858</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty='l2', fit_intercept=True,solver='libli...</td>\n",
       "      <td>add amount column</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 18:56</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>RandomOverSampler amount less</td>\n",
       "      <td>0.866580</td>\n",
       "      <td>0.014306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty='l2', fit_intercept=True,solver='libli...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-14 19:26</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>SMOTE_minority amount less</td>\n",
       "      <td>0.844703</td>\n",
       "      <td>0.014233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>penalty='l2', fit_intercept=True,solver='libli...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Modèle Features  \\\n",
       "date                                                \n",
       "2023-02-15 16:37          LGBMClassifier      ALL   \n",
       "2023-02-15 16:39  RandomForestClassifier      ALL   \n",
       "2023-01-20 16:16          LGBMClassifier    Items   \n",
       "2023-01-21 17:29          LGBMClassifier    Items   \n",
       "2023-01-21 17:31      LogisticRegression    Items   \n",
       "2023-01-20 15:29      LogisticRegression    Items   \n",
       "2023-02-15 16:36      LogisticRegression      ALL   \n",
       "2023-01-21 17:45          LGBMClassifier      ALL   \n",
       "2023-01-21 17:40      LogisticRegression      ALL   \n",
       "2023-01-21 17:35          LGBMClassifier      ALL   \n",
       "2023-02-14 14:59          LGBMClassifier      ALL   \n",
       "2023-02-14 16:56          LGBMClassifier      ALL   \n",
       "2023-02-15 15:46          LGBMClassifier      ALL   \n",
       "2023-02-14 17:04          LGBMClassifier      ALL   \n",
       "2023-02-14 17:53          LGBMClassifier      ALL   \n",
       "2023-02-13 11:00          LGBMClassifier      ALL   \n",
       "2023-02-14 15:45          LGBMClassifier      ALL   \n",
       "2023-02-15 15:48  RandomForestClassifier      ALL   \n",
       "2023-02-14 17:52      LogisticRegression      ALL   \n",
       "2023-02-14 15:42      LogisticRegression      ALL   \n",
       "2023-02-13 10:00      LogisticRegression      ALL   \n",
       "2023-02-15 15:44      LogisticRegression      ALL   \n",
       "2023-02-14 17:03      LogisticRegression      ALL   \n",
       "2023-02-14 10:55      LogisticRegression      ALL   \n",
       "2023-01-21 17:30      LogisticRegression      ALL   \n",
       "2023-02-14 16:52      LogisticRegression      ALL   \n",
       "2023-02-14 18:56      LogisticRegression      ALL   \n",
       "2023-02-14 19:26      LogisticRegression      ALL   \n",
       "\n",
       "                                       Add Data  Accuracy Score  \\\n",
       "date                                                              \n",
       "2023-02-15 16:37                BorderlineSMOTE        0.974458   \n",
       "2023-02-15 16:39                BorderlineSMOTE        0.728473   \n",
       "2023-01-20 16:16                            NaN        0.986259   \n",
       "2023-01-21 17:29  RandomOverSampler amount less        0.925989   \n",
       "2023-01-21 17:31  RandomOverSampler amount less        0.733608   \n",
       "2023-01-20 15:29                            NaN        0.985074   \n",
       "2023-02-15 16:36                BorderlineSMOTE        0.561645   \n",
       "2023-01-21 17:45  RandomOverSampler amount less        0.932220   \n",
       "2023-01-21 17:40  RandomOverSampler amount less        0.726748   \n",
       "2023-01-21 17:35                            NaN        0.986152   \n",
       "2023-02-14 14:59                            NaN        0.985936   \n",
       "2023-02-14 16:56                            NaN        0.985667   \n",
       "2023-02-15 15:46                BorderlineSMOTE        0.974458   \n",
       "2023-02-14 17:04              RandomOverSampler        0.931674   \n",
       "2023-02-14 17:53                BorderlineSMOTE        0.980440   \n",
       "2023-02-13 11:00  RandomOverSampler amount less        0.893523   \n",
       "2023-02-14 15:45  RandomOverSampler amount less        0.928387   \n",
       "2023-02-15 15:48                BorderlineSMOTE        0.728473   \n",
       "2023-02-14 17:52                BorderlineSMOTE        0.634336   \n",
       "2023-02-14 15:42              RandomOverSampler        0.606261   \n",
       "2023-02-13 10:00  RandomOverSampler amount less        0.565147   \n",
       "2023-02-15 15:44                BorderlineSMOTE        0.561645   \n",
       "2023-02-14 17:03              RandomOverSampler        0.598610   \n",
       "2023-02-14 10:55     SMOTE_minority amount less        0.545425   \n",
       "2023-01-21 17:30                            NaN        0.984966   \n",
       "2023-02-14 16:52                            NaN        0.984858   \n",
       "2023-02-14 18:56  RandomOverSampler amount less        0.866580   \n",
       "2023-02-14 19:26     SMOTE_minority amount less        0.844703   \n",
       "\n",
       "                  pr_auc_score TEST perso  avg_score  \\\n",
       "date                                                   \n",
       "2023-02-15 16:37                 0.069366   0.192252   \n",
       "2023-02-15 16:39                 0.030205   0.059238   \n",
       "2023-01-20 16:16                 0.093033   0.000000   \n",
       "2023-01-21 17:29                 0.879887   0.000000   \n",
       "2023-01-21 17:31                 0.657288   0.000000   \n",
       "2023-01-20 15:29                 0.014657   0.000000   \n",
       "2023-02-15 16:36                 0.026211   0.053348   \n",
       "2023-01-21 17:45                 0.888196   0.000000   \n",
       "2023-01-21 17:40                 0.650713   0.000000   \n",
       "2023-01-21 17:35                 0.093013   0.000000   \n",
       "2023-02-14 14:59                 0.078879   0.000000   \n",
       "2023-02-14 16:56                 0.070795   0.000000   \n",
       "2023-02-15 15:46                 0.069366   0.000000   \n",
       "2023-02-14 17:04                 0.068321   0.000000   \n",
       "2023-02-14 17:53                 0.065619   0.000000   \n",
       "2023-02-13 11:00                 0.060563   0.000000   \n",
       "2023-02-14 15:45                 0.059118   0.000000   \n",
       "2023-02-15 15:48                 0.030205   0.000000   \n",
       "2023-02-14 17:52                 0.028390   0.000000   \n",
       "2023-02-14 15:42                 0.026763   0.000000   \n",
       "2023-02-13 10:00                 0.026700   0.000000   \n",
       "2023-02-15 15:44                 0.026211   0.000000   \n",
       "2023-02-14 17:03                 0.026163   0.000000   \n",
       "2023-02-14 10:55                 0.025792   0.000000   \n",
       "2023-01-21 17:30                 0.014657   0.000000   \n",
       "2023-02-14 16:52                 0.014657   0.000000   \n",
       "2023-02-14 18:56                 0.014306   0.000000   \n",
       "2023-02-14 19:26                 0.014233   0.000000   \n",
       "\n",
       "                  pr_auc_score TEST officiel  \\\n",
       "date                                           \n",
       "2023-02-15 16:37                    0.168098   \n",
       "2023-02-15 16:39                    0.078557   \n",
       "2023-01-20 16:16                    0.078557   \n",
       "2023-01-21 17:29                    0.068491   \n",
       "2023-01-21 17:31                    0.032113   \n",
       "2023-01-20 15:29                    0.016812   \n",
       "2023-02-15 16:36                    0.000000   \n",
       "2023-01-21 17:45                    0.000000   \n",
       "2023-01-21 17:40                    0.000000   \n",
       "2023-01-21 17:35                    0.000000   \n",
       "2023-02-14 14:59                    0.000000   \n",
       "2023-02-14 16:56                    0.000000   \n",
       "2023-02-15 15:46                    0.000000   \n",
       "2023-02-14 17:04                    0.000000   \n",
       "2023-02-14 17:53                    0.000000   \n",
       "2023-02-13 11:00                    0.000000   \n",
       "2023-02-14 15:45                    0.000000   \n",
       "2023-02-15 15:48                    0.000000   \n",
       "2023-02-14 17:52                    0.000000   \n",
       "2023-02-14 15:42                    0.000000   \n",
       "2023-02-13 10:00                    0.000000   \n",
       "2023-02-15 15:44                    0.000000   \n",
       "2023-02-14 17:03                    0.000000   \n",
       "2023-02-14 10:55                    0.000000   \n",
       "2023-01-21 17:30                    0.000000   \n",
       "2023-02-14 16:52                    0.000000   \n",
       "2023-02-14 18:56                    0.000000   \n",
       "2023-02-14 19:26                    0.000000   \n",
       "\n",
       "                                                             Params  \\\n",
       "date                                                                  \n",
       "2023-02-15 16:37  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-15 16:39      random_state=42,max_depth=2,n_estimators=1000   \n",
       "2023-01-20 16:16  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-01-21 17:29  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-01-21 17:31  penalty=\"l2\", fit_intercept=True,solver='libli...   \n",
       "2023-01-20 15:29  penalty=\"l2\", fit_intercept=True,solver='libli...   \n",
       "2023-02-15 16:36  penalty='l2', fit_intercept=True,solver='libli...   \n",
       "2023-01-21 17:45  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-01-21 17:40  penalty=\"l2\", fit_intercept=True,solver='libli...   \n",
       "2023-01-21 17:35  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-14 14:59  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-14 16:56  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-15 15:46  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-14 17:04  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-14 17:53  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-13 11:00  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-14 15:45  boosting_type='goss', max_depth=5,learning_rat...   \n",
       "2023-02-15 15:48      random_state=42,max_depth=2,n_estimators=1000   \n",
       "2023-02-14 17:52  penalty='l2', fit_intercept=True,solver='libli...   \n",
       "2023-02-14 15:42  penalty='l2', fit_intercept=True,solver='libli...   \n",
       "2023-02-13 10:00  penalty=\"l2\", fit_intercept=True,solver='libli...   \n",
       "2023-02-15 15:44  penalty='l2', fit_intercept=True,solver='libli...   \n",
       "2023-02-14 17:03  penalty='l2', fit_intercept=True,solver='libli...   \n",
       "2023-02-14 10:55  penalty=l2, fit_intercept=True,solver='liblinear'   \n",
       "2023-01-21 17:30  penalty=\"l2\", fit_intercept=True,solver='libli...   \n",
       "2023-02-14 16:52  penalty='l2', fit_intercept=True,solver='libli...   \n",
       "2023-02-14 18:56  penalty='l2', fit_intercept=True,solver='libli...   \n",
       "2023-02-14 19:26  penalty='l2', fit_intercept=True,solver='libli...   \n",
       "\n",
       "                                                Commentaire  \n",
       "date                                                         \n",
       "2023-02-15 16:37                                  over data  \n",
       "2023-02-15 16:39                                  over data  \n",
       "2023-01-20 16:16                      Sans ajout de données  \n",
       "2023-01-21 17:29  AVEC ajout de données sur tout le dataset  \n",
       "2023-01-21 17:31  AVEC ajout de données sur tout le dataset  \n",
       "2023-01-20 15:29                      Sans ajout de données  \n",
       "2023-02-15 16:36                                        NaN  \n",
       "2023-01-21 17:45  AVEC ajout de données sur tout le dataset  \n",
       "2023-01-21 17:40  AVEC ajout de données sur tout le dataset  \n",
       "2023-01-21 17:35                      SANS ajout de données  \n",
       "2023-02-14 14:59                                        NaN  \n",
       "2023-02-14 16:56                          add amount column  \n",
       "2023-02-15 15:46                                  over data  \n",
       "2023-02-14 17:04           Add amount and Add data on train  \n",
       "2023-02-14 17:53               Amount and Add data on train  \n",
       "2023-02-13 11:00       AVEC ajout de données sur Train only  \n",
       "2023-02-14 15:45                          Add data on train  \n",
       "2023-02-15 15:48                                  over data  \n",
       "2023-02-14 17:52               Amount and Add data on train  \n",
       "2023-02-14 15:42                          Add data on train  \n",
       "2023-02-13 10:00       AVEC ajout de données sur Train only  \n",
       "2023-02-15 15:44                                        NaN  \n",
       "2023-02-14 17:03           Add amount and Add data on train  \n",
       "2023-02-14 10:55              Add data on Train on minority  \n",
       "2023-01-21 17:30                      SANS ajout de données  \n",
       "2023-02-14 16:52                          add amount column  \n",
       "2023-02-14 18:56                                        NaN  \n",
       "2023-02-14 19:26                                        NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_path = r'C:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\dataset\\score.csv'\n",
    "scores = load_scores(score_path=score_path, save_it=False, verbose=verbose)\n",
    "print(scores.shape)\n",
    "scores.sort_values([\"pr_auc_score TEST officiel\",\"avg_score\",\"pr_auc_score TEST perso\"], ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Blue; padding: 15px;\" >\n",
    "\n",
    "## 3.Modèles Recherche du modèle le plus adapté\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Green; padding: 7px;\" >\n",
    "\n",
    "### 3.1. Essai premier modèle sur item uniquement sans traitement\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### 3.1.1. LogisticRegression\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_model         ]\tINFO  accuracy score : 0.5616445737687251, pr_auc score : 0.0262114591378106, average_precision_score : 0.053347993953716116                          \n",
      "[predict_official_testset]\tINFO  Prediction for test origine...                          \n"
     ]
    }
   ],
   "source": [
    "# accuracy score : 0.9848043970255416, pr_auc score : 0.014656751805151417\n",
    "# accuracy score : 0.9848582821424723, pr_auc score : 0.014656751805151417\n",
    "# accuracy score : 0.5616445737687251, pr_auc score : 0.0262114591378106\n",
    "# accuracy score : 0.5616445737687251, pr_auc score : 0.0262114591378106, average_precision_score : 0.053347993953716116 \n",
    "model_LR, n_scores = train_LogisticRegression(dataset_dict=dataset_dict, data_set_path=data_set_path, \n",
    "                            scores=scores, score_path=score_path, \n",
    "                            features=\"ALL\", add_data=over_name,commentaire=np.nan, \n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\WORK\\\\workspace-ia\\\\PROJETS\\\\projet_bnp_paribas_fraudeurs\\\\model\\\\train_complete_encoded_hyper_light_2023_01_192023-02-15_16-37_LogisticRegression.pickle'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model=model_LR, model_name=\"LogisticRegression\", model_path=model_path, train_file_name=train_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = n_scores\n",
    "save_score(n_scores, score_path=score_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### 3.1.2. LGBMClassifier\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_model         ]\tINFO  accuracy score : 0.9744584545748465, pr_auc score : 0.0693657858160973, average_precision_score : 0.19225228724538732                          \n",
      "[predict_official_testset]\tINFO  Prediction for test origine...                          \n"
     ]
    }
   ],
   "source": [
    "# previously       0.9861515249488091 and 0.09301333707479051\n",
    "# accuracy score : 0.9859359844810863, pr_auc score : 0.07887944011003084\n",
    "# accuracy score : 0.9856665588964328, pr_auc score : 0.07079502735462112\n",
    "# accuracy score : 0.9744584545748465, pr_auc score : 0.0693657858160973\n",
    "# accuracy score : 0.9744584545748465, pr_auc score : 0.0693657858160973, average_precision_score : 0.19225228724538732                          \n",
    "model_LGBMC, n_scores = train_LGBMClassifier(dataset_dict=dataset_dict, data_set_path=data_set_path, \n",
    "                            scores=scores, score_path=score_path, \n",
    "                            features=\"ALL\", add_data=over_name,commentaire=\"over data\", \n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\WORK\\\\workspace-ia\\\\PROJETS\\\\projet_bnp_paribas_fraudeurs\\\\model\\\\train_complete_encoded_hyper_light_2023_01_192023-02-15_16-38_LGBMClassifier.pickle'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model=model_LGBMC, model_name=\"LGBMClassifier\", model_path=model_path, train_file_name=train_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = n_scores\n",
    "save_score(n_scores, score_path=score_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>fraud_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64707</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63919</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15664</td>\n",
       "      <td>0.000696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6626</td>\n",
       "      <td>0.003961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26766</td>\n",
       "      <td>0.044592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23193</th>\n",
       "      <td>63474</td>\n",
       "      <td>0.001855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23194</th>\n",
       "      <td>80438</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23195</th>\n",
       "      <td>29485</td>\n",
       "      <td>0.003283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23196</th>\n",
       "      <td>59838</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23197</th>\n",
       "      <td>110584</td>\n",
       "      <td>0.084677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  fraud_flag\n",
       "index                    \n",
       "0       64707    0.000074\n",
       "1       63919    0.000150\n",
       "2       15664    0.000696\n",
       "3        6626    0.003961\n",
       "4       26766    0.044592\n",
       "...       ...         ...\n",
       "23193   63474    0.001855\n",
       "23194   80438    0.000001\n",
       "23195   29485    0.003283\n",
       "23196   59838    0.000009\n",
       "23197  110584    0.084677\n",
       "\n",
       "[23198 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_official_testset(model=model_LGBMC, test_origin=test_origin, data_set_path=data_set_path, model_name=\"LGBMClassifier\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### 3.1.3. RandomForestClassifier\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_model         ]\tINFO  accuracy score : 0.7284728957861839, pr_auc score : 0.03020458857127751, average_precision_score : 0.05923769604695387                          \n",
      "[predict_official_testset]\tINFO  Prediction for test origine...                          \n"
     ]
    }
   ],
   "source": [
    "# accuracy score : 0.7284728957861839, pr_auc score : 0.03020458857127751\n",
    "# accuracy score : 0.7284728957861839, pr_auc score : 0.03020458857127751, average_precision_score : 0.05923769604695387\n",
    "model_RF, n_scores = train_RandomForestClassifier(dataset_dict=dataset_dict, data_set_path=data_set_path, \n",
    "                            scores=scores, score_path=score_path, \n",
    "                            features=\"ALL\", add_data=over_name,commentaire=\"over data\", \n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\WORK\\\\workspace-ia\\\\PROJETS\\\\projet_bnp_paribas_fraudeurs\\\\model\\\\train_complete_encoded_hyper_light_2023_01_192023-02-15_16-39_RandomForestClassifier.pickle'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model=model_RF, model_name=\"RandomForestClassifier\", model_path=model_path, train_file_name=train_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = n_scores\n",
    "save_score(n_scores, score_path=score_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>fraud_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64707</td>\n",
       "      <td>0.434482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63919</td>\n",
       "      <td>0.431827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15664</td>\n",
       "      <td>0.481099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6626</td>\n",
       "      <td>0.498964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26766</td>\n",
       "      <td>0.538869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23193</th>\n",
       "      <td>63474</td>\n",
       "      <td>0.441055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23194</th>\n",
       "      <td>80438</td>\n",
       "      <td>0.403146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23195</th>\n",
       "      <td>29485</td>\n",
       "      <td>0.539257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23196</th>\n",
       "      <td>59838</td>\n",
       "      <td>0.420155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23197</th>\n",
       "      <td>110584</td>\n",
       "      <td>0.562191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  fraud_flag\n",
       "index                    \n",
       "0       64707    0.434482\n",
       "1       63919    0.431827\n",
       "2       15664    0.481099\n",
       "3        6626    0.498964\n",
       "4       26766    0.538869\n",
       "...       ...         ...\n",
       "23193   63474    0.441055\n",
       "23194   80438    0.403146\n",
       "23195   29485    0.539257\n",
       "23196   59838    0.420155\n",
       "23197  110584    0.562191\n",
       "\n",
       "[23198 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_official_testset(model=model_RF, test_origin=test_origin, data_set_path=data_set_path, model_name=\"RandomForestClassifier\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### 3.1.4. AdaBoostClassifier\n",
    "</div>\n",
    "\n",
    "https://towardsdatascience.com/comparing-different-classification-machine-learning-models-for-an-imbalanced-dataset-fdae1af3677f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_model         ]\tINFO  accuracy score : 0.921058303696519, pr_auc score : 0.04879315820764524, average_precision_score : 0.14987561051491435                          \n",
      "[predict_official_testset]\tINFO  Prediction for test origine...                          \n"
     ]
    }
   ],
   "source": [
    "# accuracy score : 0.921058303696519, pr_auc score : 0.04879315820764524, average_precision_score : 0.14987561051491435\n",
    "model_ABC, n_scores = train_AdaBoostClassifier(dataset_dict=dataset_dict, data_set_path=data_set_path, \n",
    "                            scores=scores, score_path=score_path, \n",
    "                            features=\"ALL\", add_data=over_name,commentaire=\"over data\", \n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\WORK\\\\workspace-ia\\\\PROJETS\\\\projet_bnp_paribas_fraudeurs\\\\model\\\\train_complete_encoded_hyper_light_2023_01_192023-02-15_18-53_AdaBoostClassifier.pickle'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model=model_ABC, model_name=\"AdaBoostClassifier\", model_path=model_path, train_file_name=train_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = n_scores\n",
    "save_score(n_scores, score_path=score_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### 3.1.4. GradientBoostingClassifier\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\bnp_paribas_Model.ipynb Cellule 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/WORK/workspace-ia/PROJETS/projet_bnp_paribas_fraudeurs/bnp_paribas_Model.ipynb#Y123sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model, n_scores \u001b[39m=\u001b[39m train_GradientBoostingClassifier(dataset_dict\u001b[39m=\u001b[39;49mdataset_dict, data_set_path\u001b[39m=\u001b[39;49mdata_set_path, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/WORK/workspace-ia/PROJETS/projet_bnp_paribas_fraudeurs/bnp_paribas_Model.ipynb#Y123sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                             scores\u001b[39m=\u001b[39;49mscores, score_path\u001b[39m=\u001b[39;49mscore_path, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/WORK/workspace-ia/PROJETS/projet_bnp_paribas_fraudeurs/bnp_paribas_Model.ipynb#Y123sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                             features\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mALL\u001b[39;49m\u001b[39m\"\u001b[39;49m, add_data\u001b[39m=\u001b[39;49mover_name,commentaire\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mover data\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/WORK/workspace-ia/PROJETS/projet_bnp_paribas_fraudeurs/bnp_paribas_Model.ipynb#Y123sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                             verbose\u001b[39m=\u001b[39;49mverbose)\n",
      "File \u001b[1;32mc:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\bnp_paribas.py:628\u001b[0m, in \u001b[0;36mtrain_GradientBoostingClassifier\u001b[1;34m(dataset_dict, data_set_path, scores, score_path, features, add_data, commentaire, random_state, max_depth, n_estimators, verbose)\u001b[0m\n\u001b[0;32m    625\u001b[0m my_fist_model \u001b[39m=\u001b[39m GradientBoostingClassifier(max_depth\u001b[39m=\u001b[39mmax_depth, random_state\u001b[39m=\u001b[39mrandom_state, n_estimators\u001b[39m=\u001b[39mn_estimators)\n\u001b[0;32m    626\u001b[0m params\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrandom_state=\u001b[39m\u001b[39m{\u001b[39;00mrandom_state\u001b[39m}\u001b[39;00m\u001b[39m,max_depth=\u001b[39m\u001b[39m{\u001b[39;00mmax_depth\u001b[39m}\u001b[39;00m\u001b[39m,n_estimators=\u001b[39m\u001b[39m{\u001b[39;00mn_estimators\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 628\u001b[0m model, n_scores \u001b[39m=\u001b[39m train_model(model\u001b[39m=\u001b[39;49mmy_fist_model, model_name\u001b[39m=\u001b[39;49mmodel_name, \n\u001b[0;32m    629\u001b[0m                             dataset_dict\u001b[39m=\u001b[39;49mdataset_dict, data_set_path\u001b[39m=\u001b[39;49mdata_set_path, scores\u001b[39m=\u001b[39;49mscores, score_path\u001b[39m=\u001b[39;49mscore_path, params\u001b[39m=\u001b[39;49mparams, features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[0;32m    630\u001b[0m                             add_data\u001b[39m=\u001b[39;49madd_data,commentaire\u001b[39m=\u001b[39;49mcommentaire, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[0;32m    632\u001b[0m \u001b[39mreturn\u001b[39;00m model, n_scores\n",
      "File \u001b[1;32mc:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\bnp_paribas.py:529\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, model_name, dataset_dict, data_set_path, scores, score_path, params, features, add_data, commentaire, target, verbose)\u001b[0m\n\u001b[0;32m    527\u001b[0m short_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrain_model\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m \u001b[39mif\u001b[39;00m verbose\u001b[39m>\u001b[39m\u001b[39m1\u001b[39m:debug(short_name, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m model fiting...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 529\u001b[0m model\u001b[39m.\u001b[39;49mfit(dataset_dict\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mX_train\u001b[39;49m\u001b[39m\"\u001b[39;49m), dataset_dict\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39my_train\u001b[39;49m\u001b[39m\"\u001b[39;49m)[target])\n\u001b[0;32m    531\u001b[0m \u001b[39mif\u001b[39;00m verbose\u001b[39m>\u001b[39m\u001b[39m1\u001b[39m:debug(short_name,\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel evaluation...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    532\u001b[0m score_accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mscore(dataset_dict\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mX_test\u001b[39m\u001b[39m\"\u001b[39m), dataset_dict\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39my_test\u001b[39m\u001b[39m\"\u001b[39m)[target])\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:668\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[0;32m    667\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 668\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stages(\n\u001b[0;32m    669\u001b[0m     X,\n\u001b[0;32m    670\u001b[0m     y,\n\u001b[0;32m    671\u001b[0m     raw_predictions,\n\u001b[0;32m    672\u001b[0m     sample_weight,\n\u001b[0;32m    673\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[0;32m    674\u001b[0m     X_val,\n\u001b[0;32m    675\u001b[0m     y_val,\n\u001b[0;32m    676\u001b[0m     sample_weight_val,\n\u001b[0;32m    677\u001b[0m     begin_at_stage,\n\u001b[0;32m    678\u001b[0m     monitor,\n\u001b[0;32m    679\u001b[0m )\n\u001b[0;32m    681\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:745\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    738\u001b[0m     old_oob_score \u001b[39m=\u001b[39m loss_(\n\u001b[0;32m    739\u001b[0m         y[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    740\u001b[0m         raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    741\u001b[0m         sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    742\u001b[0m     )\n\u001b[0;32m    744\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stage(\n\u001b[0;32m    746\u001b[0m     i,\n\u001b[0;32m    747\u001b[0m     X,\n\u001b[0;32m    748\u001b[0m     y,\n\u001b[0;32m    749\u001b[0m     raw_predictions,\n\u001b[0;32m    750\u001b[0m     sample_weight,\n\u001b[0;32m    751\u001b[0m     sample_mask,\n\u001b[0;32m    752\u001b[0m     random_state,\n\u001b[0;32m    753\u001b[0m     X_csc,\n\u001b[0;32m    754\u001b[0m     X_csr,\n\u001b[0;32m    755\u001b[0m )\n\u001b[0;32m    757\u001b[0m \u001b[39m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    758\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:247\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    244\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m sample_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m    246\u001b[0m X \u001b[39m=\u001b[39m X_csr \u001b[39mif\u001b[39;00m X_csr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\n\u001b[1;32m--> 247\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X, residual, sample_weight\u001b[39m=\u001b[39;49msample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    249\u001b[0m \u001b[39m# update tree leaves\u001b[39;00m\n\u001b[0;32m    250\u001b[0m loss\u001b[39m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    251\u001b[0m     tree\u001b[39m.\u001b[39mtree_,\n\u001b[0;32m    252\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    259\u001b[0m     k\u001b[39m=\u001b[39mk,\n\u001b[0;32m    260\u001b[0m )\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\sklearn\\tree\\_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1314\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \n\u001b[0;32m   1316\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1342\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1343\u001b[0m         X,\n\u001b[0;32m   1344\u001b[0m         y,\n\u001b[0;32m   1345\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1346\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1347\u001b[0m     )\n\u001b[0;32m   1348\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\sklearn\\tree\\_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    449\u001b[0m         splitter,\n\u001b[0;32m    450\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    456\u001b[0m     )\n\u001b[1;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_GB, n_scores = train_GradientBoostingClassifier(dataset_dict=dataset_dict, data_set_path=data_set_path, \n",
    "                            scores=scores, score_path=score_path, \n",
    "                            features=\"ALL\", add_data=over_name,commentaire=\"over data\", \n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model=model_GB, model_name=\"GradientBoostingClassifier\", model_path=model_path, train_file_name=train_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = n_scores\n",
    "save_score(n_scores, score_path=score_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Green; padding: 7px;\" >\n",
    "\n",
    "### 3.2. D'après scikit-learn\n",
    "</div>\n",
    "\n",
    "A tester dans l'ordre :\n",
    "\n",
    "1. <mark>**Linear_SVC**</mark> : LinearSVC\n",
    "1. <mark>**KNeightbors Classifier**</mark> : NearestNeighbors, KDTree or BallTree, KNeighborsClassifier \n",
    "   - all this model can handle either NumPy arrays or scipy.sparse matrices as input\n",
    "1. <mark>**SVC (not linear) / Ensemble Classifiers**</mark> : \n",
    "   - SVC and NuSVC are similar methods\n",
    "   - averaging methods : Bagging methods : `BaggingClassifier`, Forests of randomized trees : `RandomForestClassifier`, …\n",
    "   - boosting methods : AdaBoost, Gradient Tree Boosting, ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Blue; padding: 15px;\" >\n",
    "\n",
    "## 4.Test des models avec les données ajoutées\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict_over = deepcopy(dataset_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Green; padding: 7px;\" >\n",
    "\n",
    "### 4.2. Ajout de données avec SMOTE :  Synthetic Minority Oversampling Technique\n",
    "</div>\n",
    "\n",
    "https://kobia.fr/imbalanced-data-et-machine-learning/\n",
    "\n",
    "> Le sur-échantillonnage synthétique (SMOTE pour Synthetic Minority Oversampling Technique) est une méthode plus avancée, qui produit des observations minoritaires ressemblantes mais distinctes de celles déjà existantes. Pour plus de précisions, vous pouvez consulter notre article dédié au SMOTE.\n",
    "\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[over_SMOTE          ]\tINFO  (146370, 1982), (146370,)                          \n",
      "[over_SMOTE          ]\tINFO  c:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\dataset\\train_complete_OVER_SMOTE_minority_encoded_hyper_light_2023_01_19.csv \u001b[6;30;42mSAVE\u001b[0m                          \n"
     ]
    }
   ],
   "source": [
    "dataset_over_SMOTE = over_dataset_with_SMOTE(X_train,y_train, data_set_path=data_set_train_file_name, \n",
    "                     sampling_strategy='minority', random_state=random_state, target = target, verbose=verbose)\n",
    "\n",
    "X_train_over = dataset_over_SMOTE.drop(target, axis=1)\n",
    "y_train_over = complete_y_cols(X_train_over, y_param=dataset_over_SMOTE[target])\n",
    "\n",
    "dataset_dict_over_SMOTE = deepcopy(dataset_dict)\n",
    "dataset_dict_over_SMOTE['X_train'] = X_train_over\n",
    "dataset_dict_over_SMOTE['y_train'] = y_train_over"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### M.4.2. LogisticRegression\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5454251535725833, 0.025792401467034952\n",
    "# Fail not enought memory (2.16 GiB)\n",
    "model, n_scores = train_LogisticRegression(dataset_dict=dataset_dict_over_SMOTE, data_set_path=data_set_path, \n",
    "                            scores=scores, score_path=score_path, \n",
    "                            features=\"ALL\", add_data=\"SMOTE\",commentaire=\"Amount and Add data on train\", \n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = n_scores\n",
    "save_score(n_scores, score_path=score_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### M.4.3. LGBMClassifier\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.16 GiB for an array with shape (1982, 146370) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\bnp_paribas_EDA_all.ipynb Cellule 79\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/WORK/workspace-ia/PROJETS/projet_bnp_paribas_fraudeurs/bnp_paribas_EDA_all.ipynb#Y260sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 0.9706864963896972 and fail\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/WORK/workspace-ia/PROJETS/projet_bnp_paribas_fraudeurs/bnp_paribas_EDA_all.ipynb#Y260sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m lgb_classifier, n_scores \u001b[39m=\u001b[39m train_LGBMClassifier(dataset_dict\u001b[39m=\u001b[39;49mdataset_dict_over_SMOTE, data_set_path\u001b[39m=\u001b[39;49mdata_set_path, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/WORK/workspace-ia/PROJETS/projet_bnp_paribas_fraudeurs/bnp_paribas_EDA_all.ipynb#Y260sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                             scores\u001b[39m=\u001b[39;49mscores, score_path\u001b[39m=\u001b[39;49mscore_path, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/WORK/workspace-ia/PROJETS/projet_bnp_paribas_fraudeurs/bnp_paribas_EDA_all.ipynb#Y260sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                             features\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mALL\u001b[39;49m\u001b[39m\"\u001b[39;49m,  add_data\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSMOTE\u001b[39;49m\u001b[39m\"\u001b[39;49m,commentaire\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mAmount and Add data on train\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/WORK/workspace-ia/PROJETS/projet_bnp_paribas_fraudeurs/bnp_paribas_EDA_all.ipynb#Y260sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                             verbose\u001b[39m=\u001b[39;49mverbose)\n",
      "File \u001b[1;32mc:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\bnp_paribas.py:489\u001b[0m, in \u001b[0;36mtrain_LGBMClassifier\u001b[1;34m(dataset_dict, data_set_path, scores, score_path, features, add_data, commentaire, verbose)\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[39mreturn\u001b[39;00m model, n_scores\n\u001b[0;32m    487\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m    488\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_LogisticRegression\u001b[39m(dataset_dict, data_set_path, \n\u001b[1;32m--> 489\u001b[0m                             scores, score_path, \n\u001b[0;32m    490\u001b[0m                             features\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mALL\u001b[39m\u001b[39m\"\u001b[39m, add_data\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan,commentaire\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan, \n\u001b[0;32m    491\u001b[0m                             verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m    493\u001b[0m     \u001b[39mif\u001b[39;00m verbose\u001b[39m>\u001b[39m\u001b[39m1\u001b[39m:\u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel creation...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    494\u001b[0m     my_fist_model \u001b[39m=\u001b[39m LogisticRegression(penalty\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m\"\u001b[39m, fit_intercept\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\bnp_paribas.py:430\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, model_name, dataset_dict, data_set_path, scores, score_path, params, features, add_data, commentaire, target, verbose)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop_numeroted_data_col\u001b[39m(df, cols_name, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m    429\u001b[0m     short_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdrop_numeroted_data_col\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 430\u001b[0m     n_df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    431\u001b[0m     nb_col_droped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \n\u001b[0;32m    432\u001b[0m     \u001b[39mif\u001b[39;00m verbose\u001b[39m>\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\lightgbm\\sklearn.py:967\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    964\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m             valid_sets[i] \u001b[39m=\u001b[39m (valid_x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_le\u001b[39m.\u001b[39mtransform(valid_y))\n\u001b[1;32m--> 967\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, _y, sample_weight\u001b[39m=\u001b[39;49msample_weight, init_score\u001b[39m=\u001b[39;49minit_score, eval_set\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[0;32m    968\u001b[0m             eval_names\u001b[39m=\u001b[39;49meval_names, eval_sample_weight\u001b[39m=\u001b[39;49meval_sample_weight,\n\u001b[0;32m    969\u001b[0m             eval_class_weight\u001b[39m=\u001b[39;49meval_class_weight, eval_init_score\u001b[39m=\u001b[39;49meval_init_score,\n\u001b[0;32m    970\u001b[0m             eval_metric\u001b[39m=\u001b[39;49meval_metric, early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m    971\u001b[0m             verbose\u001b[39m=\u001b[39;49mverbose, feature_name\u001b[39m=\u001b[39;49mfeature_name, categorical_feature\u001b[39m=\u001b[39;49mcategorical_feature,\n\u001b[0;32m    972\u001b[0m             callbacks\u001b[39m=\u001b[39;49mcallbacks, init_model\u001b[39m=\u001b[39;49minit_model)\n\u001b[0;32m    973\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\lightgbm\\sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    745\u001b[0m evals_result \u001b[39m=\u001b[39m {}\n\u001b[0;32m    746\u001b[0m callbacks\u001b[39m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m    749\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    750\u001b[0m     train_set\u001b[39m=\u001b[39;49mtrain_set,\n\u001b[0;32m    751\u001b[0m     num_boost_round\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_estimators,\n\u001b[0;32m    752\u001b[0m     valid_sets\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[0;32m    753\u001b[0m     valid_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[0;32m    754\u001b[0m     fobj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fobj,\n\u001b[0;32m    755\u001b[0m     feval\u001b[39m=\u001b[39;49meval_metrics_callable,\n\u001b[0;32m    756\u001b[0m     init_model\u001b[39m=\u001b[39;49minit_model,\n\u001b[0;32m    757\u001b[0m     feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[0;32m    758\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[0;32m    759\u001b[0m )\n\u001b[0;32m    761\u001b[0m \u001b[39mif\u001b[39;00m evals_result:\n\u001b[0;32m    762\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evals_result \u001b[39m=\u001b[39m evals_result\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\lightgbm\\engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39m# construct booster\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m     booster \u001b[39m=\u001b[39m Booster(params\u001b[39m=\u001b[39;49mparams, train_set\u001b[39m=\u001b[39;49mtrain_set)\n\u001b[0;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    273\u001b[0m         booster\u001b[39m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\lightgbm\\basic.py:2605\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_network(\n\u001b[0;32m   2599\u001b[0m         machines\u001b[39m=\u001b[39mmachines,\n\u001b[0;32m   2600\u001b[0m         local_listen_port\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mlocal_listen_port\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   2601\u001b[0m         listen_time_out\u001b[39m=\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_out\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m120\u001b[39m),\n\u001b[0;32m   2602\u001b[0m         num_machines\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mnum_machines\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2603\u001b[0m     )\n\u001b[0;32m   2604\u001b[0m \u001b[39m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 2605\u001b[0m train_set\u001b[39m.\u001b[39;49mconstruct()\n\u001b[0;32m   2606\u001b[0m \u001b[39m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   2607\u001b[0m params\u001b[39m.\u001b[39mupdate(train_set\u001b[39m.\u001b[39mget_params())\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\lightgbm\\basic.py:1815\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1812\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_init_score_by_predictor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predictor, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, used_indices)\n\u001b[0;32m   1813\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     \u001b[39m# create train\u001b[39;00m\n\u001b[1;32m-> 1815\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, label\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel,\n\u001b[0;32m   1816\u001b[0m                     weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, group\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroup,\n\u001b[0;32m   1817\u001b[0m                     init_score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_score, predictor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predictor,\n\u001b[0;32m   1818\u001b[0m                     silent\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msilent, feature_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_name,\n\u001b[0;32m   1819\u001b[0m                     categorical_feature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcategorical_feature, params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[0;32m   1820\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfree_raw_data:\n\u001b[0;32m   1821\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\lightgbm\\basic.py:1474\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1472\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpandas_categorical \u001b[39m=\u001b[39m reference\u001b[39m.\u001b[39mpandas_categorical\n\u001b[0;32m   1473\u001b[0m     categorical_feature \u001b[39m=\u001b[39m reference\u001b[39m.\u001b[39mcategorical_feature\n\u001b[1;32m-> 1474\u001b[0m data, feature_name, categorical_feature, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpandas_categorical \u001b[39m=\u001b[39m _data_from_pandas(data,\n\u001b[0;32m   1475\u001b[0m                                                                                      feature_name,\n\u001b[0;32m   1476\u001b[0m                                                                                      categorical_feature,\n\u001b[0;32m   1477\u001b[0m                                                                                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpandas_categorical)\n\u001b[0;32m   1478\u001b[0m label \u001b[39m=\u001b[39m _label_from_pandas(label)\n\u001b[0;32m   1480\u001b[0m \u001b[39m# process for args\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\lightgbm\\basic.py:597\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    593\u001b[0m     bad_index_cols_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(data\u001b[39m.\u001b[39mcolumns[bad_indices])\n\u001b[0;32m    594\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataFrame.dtypes for data must be int, float or bool.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    595\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mDid not expect the data types in the following fields: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    596\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mbad_index_cols_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 597\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mvalues\n\u001b[0;32m    598\u001b[0m \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mfloat32 \u001b[39mand\u001b[39;00m data\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mfloat64:\n\u001b[0;32m    599\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\pandas\\core\\frame.py:10883\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  10810\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m  10811\u001b[0m \u001b[39mReturn a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  10812\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10880\u001b[0m \u001b[39m       ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  10881\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m  10882\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[1;32m> 10883\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array()\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1589\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1587\u001b[0m             arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1588\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1589\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[0;32m   1590\u001b[0m     \u001b[39m# The underlying data was copied within _interleave\u001b[39;00m\n\u001b[0;32m   1591\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python_venv\\tensor_flow\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1628\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1625\u001b[0m \u001b[39melif\u001b[39;00m is_dtype_equal(dtype, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1626\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1628\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m   1630\u001b[0m itemmask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m   1632\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m na_value \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n\u001b[0;32m   1633\u001b[0m     \u001b[39m# much more performant than using to_numpy below\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.16 GiB for an array with shape (1982, 146370) and data type float64"
     ]
    }
   ],
   "source": [
    "# 0.9706864963896972 and fail\n",
    "# Fail not enought memory (2.16 GiB)\n",
    "lgb_classifier, n_scores = train_LGBMClassifier(dataset_dict=dataset_dict_over_SMOTE, data_set_path=data_set_path, \n",
    "                            scores=scores, score_path=score_path, \n",
    "                            features=\"ALL\",  add_data=\"SMOTE\",commentaire=\"Amount and Add data on train\", \n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = n_scores\n",
    "save_score(n_scores, score_path=score_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Green; padding: 7px;\" >\n",
    "\n",
    "### 4.2. Ajout de données avec Borderline-SMOTE2\n",
    "</div>\n",
    "\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[over_BorderlineSMOTE]\tINFO  (146370, 1982), (146370,)                          \n",
      "[over_BorderlineSMOTE]\tINFO  c:\\Users\\User\\WORK\\workspace-ia\\PROJETS\\projet_bnp_paribas_fraudeurs\\dataset\\train_complete_OVER_BorderlineSMOTE_encoded_hyper_light_2023_01_19.csv \u001b[6;30;42mSAVE\u001b[0m                          \n"
     ]
    }
   ],
   "source": [
    "dataset_over_BorderlineSMOTE = over_dataset_with_BorderlineSMOTE(X_train,y_train, data_set_path=data_set_train_file_name, \n",
    "                    target = target, verbose=verbose)\n",
    "\n",
    "X_train_over = dataset_over_BorderlineSMOTE.drop(target, axis=1)\n",
    "y_train_over = complete_y_cols(X_train_over, y_param=dataset_over_BorderlineSMOTE[target])\n",
    "\n",
    "dataset_dict_over_BorderlineSMOTE = deepcopy(dataset_dict)\n",
    "dataset_dict_over_BorderlineSMOTE['X_train'] = X_train_over\n",
    "dataset_dict_over_BorderlineSMOTE['y_train'] = y_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot_X.append(dataset_dict_over_BorderlineSMOTE[\"X_train\"])\n",
    "to_plot_y.append(dataset_dict_over_BorderlineSMOTE[\"y_train\"])\n",
    "titles.append(\"BorderlineSMOTE\")\n",
    "\n",
    "plot_scatters(Xs=to_plot_X, ys=to_plot_y,titles=titles,target=target, size=(20, 20), verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### M.4.2. LogisticRegression\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "model, n_scores = train_LogisticRegression(dataset_dict=dataset_dict_over_BorderlineSMOTE, data_set_path=data_set_path, \n",
    "                            scores=scores, score_path=score_path, \n",
    "                            features=\"ALL\", add_data=\"BorderlineSMOTE\",commentaire=\"Amount and Add data on train\", \n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = n_scores\n",
    "save_score(n_scores, score_path=score_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### M.4.3. LGBMClassifier\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "lgb_classifier, n_scores = train_LGBMClassifier(dataset_dict=dataset_dict_over_BorderlineSMOTE, data_set_path=data_set_path, \n",
    "                            scores=scores, score_path=score_path, \n",
    "                            features=\"ALL\",  add_data=\"BorderlineSMOTE\",commentaire=\"Amount and Add data on train\", \n",
    "                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = n_scores\n",
    "save_score(n_scores, score_path=score_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Blue; padding: 15px;\" >\n",
    "\n",
    "## 5.Modèles Recherche du modèle le plus adapté\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Green; padding: 7px;\" >\n",
    "\n",
    "### M.2. Recherche manuelle\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/comparing-different-classification-machine-learning-models-for-an-imbalanced-dataset-fdae1af3677f\n",
    "\n",
    "Logistic Regression, K Nearest Neighbors, Gradient Boosting Classifier, Decision Tree, Random Forest, Neural Net."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Green; padding: 7px;\" >\n",
    "\n",
    "### M.2. hyperparameter tuning algorithms (Grid Search)\n",
    "</div>\n",
    "\n",
    "There are three popular hyperparameter tuning algorithms that you may choose from:\n",
    "\n",
    "    Random Search\n",
    "    Grid Search\n",
    "    Bayesian Optimization\n",
    "\n",
    "A good default is grid search if you know what hyperparameter values to try, otherwise, random search should be used. Bayesian optimization should be used if possible but can be more challenging to set up and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Green; padding: 7px;\" >\n",
    "\n",
    "### M.1. Théories avant réalisation\n",
    "</div>\n",
    "\n",
    "\n",
    "Sources : \n",
    "- https://blog.octo.com/donnees-desequilibrees-que-faire/\n",
    "\n",
    "Idées : \n",
    "- approche naïve de classification ?  LightGBM et un Stochastic Gradient Descent ?\n",
    "\n",
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### M.1.1. Choisir les bonnes métriques\n",
    "</div>\n",
    "\n",
    "Métriques : Choisir la métrique la plus pertinente d’un point de vue métier\n",
    "- <mark>accuracy</mark> non pertinente\n",
    "- Le <mark>rappel</mark> indique la capacité du modèle à prédire correctement tous les positifs et la précision indique la capacité du modèle à ne prédire que les positifs.\n",
    "- <mark>score F1</mark> : est très intéressant quand il existe un double enjeu et qu’on cherche à avoir à la fois un bon rappel et une bonne précision.  Il s’agit d’une moyenne des deux métriques\n",
    "- Le coefficient de corrélation de <mark>Matthews</mark> ou le <mark>MCC</mark> reste la meilleure métrique à utiliser : Concrètement, si on considère que la classe prédite et la classe réelle sont deux variables binaires, le MCC représente la corrélation entre ces deux variables. C’est une métrique qui est symétrique et insensible au déséquilibre de classes.\n",
    "\n",
    "<div style=\"display: flex; background-color: indigo;\" >\n",
    "\n",
    "#### M.1.2. Traitement des données\n",
    "</div>\n",
    "\n",
    "Techniques de traitement\n",
    "- Techniques se basant sur l’amélioration du jeu de données\n",
    "- Techniques se basant sur l’amélioration de la phase de modélisation \n",
    "\n",
    "\n",
    "Lorsque le dataset n’est pas assez grand, on peut sur-échantillonner les observations associées à la classe la moins prépondérante. On peut générer de nouveaux échantillons par répétition de façon aléatoire ou en s’appuyant sur des méthodes un peu plus sophistiquées comme SMOTE ou ADASYN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; background-color: Blue; padding: 15px;\" >\n",
    "\n",
    "## Z.Annexe\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idées / Questions :\n",
    "- Ajouter une colonne montant total\n",
    "- Ajouter une colonne nombre total d'article ?\n",
    "- Une catégorie d'article est-elle envisageable ?\n",
    "- Regroupement par tranche de prix des articles ? des paniers ?\n",
    "- Est-ce que certains articles sont plus soumis aux fraudes que d'autres ?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Modèle|Add Data|Features|Params|Accuracy Score|pr_auc_score TEST perso|pr_auc_score TEST officiel|Commentaire|\n",
    "|------|--------|--------|------|--------------|-----------------------|--------------------------|-----------|\n",
    "|LogisticRegression||Items|penalty=\"l2\", fit_intercept=True,solver='liblinear'|0.985073822610195|0.014656751805151417|0,0168117941201828|Sans ajout de données|\n",
    "|LGBMClassifier||Items|boosting_type='goss', max_depth=5,learning_rate=0.1,n_estimators=1000,subsample=0.8,colsample_bytree=0.6|0.9862592951826705|0.09303255321981446|0,07855741945152836|Sans ajout de données|\n",
    "|LogisticRegression|RandomOverSampler|Items|penalty=\"l2\", fit_intercept=True,solver='liblinear'|0.7336084615594851|0.6572881928321739|0,03211346653991237|AVEC ajout de données sur tout le dataset|\n",
    "|LGBMClassifier|RandomOverSampler|Items|boosting_type='goss', max_depth=5,learning_rate=0.1,n_estimators=1000,subsample=0.8,colsample_bytree=0.6|0.9259886851239444|0.8798873204426053|0,06849072266219955|AVEC ajout de données sur tout le dataset|\n",
    "|LogisticRegression||ALL|penalty=\"l2\", fit_intercept=True,solver='liblinear'|0.9849660523763336|0.014656751805151417| |SANS ajout de données|\n",
    "|LGBMClassifier||ALL|boosting_type='goss', max_depth=5,learning_rate=0.1,n_estimators=1000,subsample=0.8,colsample_bytree=0.6|0.9861515249488091|0.09301333707479051| |SANS ajout de données|\n",
    "|LogisticRegression|RandomOverSampler|ALL|penalty=\"l2\", fit_intercept=True,solver='liblinear'|0.7267484763180191|0.6507125123342998| |AVEC ajout de données sur tout le dataset|\n",
    "|LGBMClassifier|RandomOverSampler|ALL|boosting_type='goss', max_depth=5,learning_rate=0.1,n_estimators=1000,subsample=0.8,colsample_bytree=0.6|0.9322200661400968|0.8881964612621873| |AVEC ajout de données sur tout le dataset|\n",
    "|LogisticRegression|RandomOverSampler|ALL|penalty=\"l2\", fit_intercept=True,solver='liblinear'|0.5651471063692208|0.026699804461301335| |AVEC ajout de données sur Train only|\n",
    "|LGBMClassifier|RandomOverSampler|ALL|boosting_type='goss', max_depth=5,learning_rate=0.1,n_estimators=1000,subsample=0.8,colsample_bytree=0.6|0.8935230089449294|0.060563220710355574| |AVEC ajout de données sur Train only|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9861515249488091\n",
      "0.09301333707479051\n"
     ]
    }
   ],
   "source": [
    "lgb_classifier = lgb.LGBMClassifier(boosting_type='goss',  \n",
    "                                    max_depth=5, \n",
    "                                    learning_rate=0.1,\n",
    "                                    n_estimators=1000, \n",
    "                                    subsample=0.8,  \n",
    "                                    colsample_bytree=0.6,\n",
    "                                   )\n",
    "classifier = lgb_classifier.fit(X_train, y_train, verbose=verbose) \n",
    "score_accuracy = classifier.score(X_test, y_test)\n",
    "print(score_accuracy)\n",
    "y_pred = classifier.predict(X_test)\n",
    "pr_auc_score_, y_t_c, y_p_c = evaluate(X_test=X_test, y_test=y_test, y_pred=y_pred, verbose=verbose)\n",
    "print(pr_auc_score_)\n",
    "\n",
    "y_pred_test = classifier.predict(test_origin)\n",
    "y_pred_test_complete = complete_y_cols(X_test=test_origin, y_param=y_pred_test)\n",
    "res_path = join(data_set_path, \"All_LGBMClassifier_\"+datetime.now().strftime('%Y-%m-%d-%H_%M')+\".csv\")\n",
    "y_pred_test_complete.to_csv(res_path)\n",
    "\n",
    "n_scores = add_score(scores_param=scores, modele=\"LGBMClassifier\", features=\"ALL\", add_data=np.nan, \n",
    "          params=\"boosting_type='goss', max_depth=5,learning_rate=0.1,n_estimators=1000.subsample=0.8,colsample_bytree=0.6\", \n",
    "          accuracy_score=score_accuracy, pr_auc_score_TEST_perso=pr_auc_score_,\n",
    "          commentaire=np.nan,\n",
    "          score_path=score_path.replace(\".csv\", f\"{datetime.now().strftime('%Y-%m-%d_%H-%M')}.csv\"),\n",
    "          verbose=verbose)\n",
    "n_scores.sort_values(by=['Modèle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>Nb_of_items</th>\n",
       "      <th>item_BED LINEN_nb</th>\n",
       "      <th>item_BED LINEN_cash</th>\n",
       "      <th>item_BATHROOM_nb</th>\n",
       "      <th>item_BATHROOM_cash</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_nb</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_cash</th>\n",
       "      <th>item_TOYS_nb</th>\n",
       "      <th>...</th>\n",
       "      <th>make_BLUEBELLA_cash</th>\n",
       "      <th>make_ROLSER_nb</th>\n",
       "      <th>make_ROLSER_cash</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_nb</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_cash</th>\n",
       "      <th>make_TEMPLE ISLAND_nb</th>\n",
       "      <th>make_TEMPLE ISLAND_cash</th>\n",
       "      <th>make_GHD_nb</th>\n",
       "      <th>make_GHD_cash</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12214</td>\n",
       "      <td>79535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21619</td>\n",
       "      <td>56408</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1635.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18886</td>\n",
       "      <td>14674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85690</td>\n",
       "      <td>33513</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30417</td>\n",
       "      <td>65918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74227</th>\n",
       "      <td>6265</td>\n",
       "      <td>5177</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74228</th>\n",
       "      <td>54886</td>\n",
       "      <td>77904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74229</th>\n",
       "      <td>76820</td>\n",
       "      <td>83123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74230</th>\n",
       "      <td>860</td>\n",
       "      <td>52208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74231</th>\n",
       "      <td>15795</td>\n",
       "      <td>69952</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2598.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74232 rows × 1982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     ID  Nb_of_items  item_BED LINEN_nb  item_BED LINEN_cash  \\\n",
       "0      12214  79535          1.0                0.0                  0.0   \n",
       "1      21619  56408          3.0                0.0                  0.0   \n",
       "2      18886  14674          1.0                0.0                  0.0   \n",
       "3      85690  33513          3.0                0.0                  0.0   \n",
       "4      30417  65918          1.0                0.0                  0.0   \n",
       "...      ...    ...          ...                ...                  ...   \n",
       "74227   6265   5177          3.0                0.0                  0.0   \n",
       "74228  54886  77904          1.0                0.0                  0.0   \n",
       "74229  76820  83123          1.0                0.0                  0.0   \n",
       "74230    860  52208          1.0                0.0                  0.0   \n",
       "74231  15795  69952          2.0                0.0                  0.0   \n",
       "\n",
       "       item_BATHROOM_nb  item_BATHROOM_cash  \\\n",
       "0                   0.0                 0.0   \n",
       "1                   0.0                 0.0   \n",
       "2                   0.0                 0.0   \n",
       "3                   0.0                 0.0   \n",
       "4                   0.0                 0.0   \n",
       "...                 ...                 ...   \n",
       "74227               0.0                 0.0   \n",
       "74228               0.0                 0.0   \n",
       "74229               0.0                 0.0   \n",
       "74230               0.0                 0.0   \n",
       "74231               0.0                 0.0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_nb  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "74227                                   0.0   \n",
       "74228                                   0.0   \n",
       "74229                                   0.0   \n",
       "74230                                   0.0   \n",
       "74231                                   0.0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_cash  item_TOYS_nb  ...  \\\n",
       "0                                         0.0           0.0  ...   \n",
       "1                                         0.0           0.0  ...   \n",
       "2                                         0.0           0.0  ...   \n",
       "3                                         0.0           0.0  ...   \n",
       "4                                         0.0           0.0  ...   \n",
       "...                                       ...           ...  ...   \n",
       "74227                                     0.0           0.0  ...   \n",
       "74228                                     0.0           0.0  ...   \n",
       "74229                                     0.0           0.0  ...   \n",
       "74230                                     0.0           0.0  ...   \n",
       "74231                                     0.0           0.0  ...   \n",
       "\n",
       "       make_BLUEBELLA_cash  make_ROLSER_nb  make_ROLSER_cash  \\\n",
       "0                      0.0             0.0               0.0   \n",
       "1                      0.0             0.0               0.0   \n",
       "2                      0.0             0.0               0.0   \n",
       "3                      0.0             0.0               0.0   \n",
       "4                      0.0             0.0               0.0   \n",
       "...                    ...             ...               ...   \n",
       "74227                  0.0             0.0               0.0   \n",
       "74228                  0.0             0.0               0.0   \n",
       "74229                  0.0             0.0               0.0   \n",
       "74230                  0.0             0.0               0.0   \n",
       "74231                  0.0             0.0               0.0   \n",
       "\n",
       "       make_DARTINGTON CRYSTAL_nb  make_DARTINGTON CRYSTAL_cash  \\\n",
       "0                             0.0                           0.0   \n",
       "1                             0.0                           0.0   \n",
       "2                             0.0                           0.0   \n",
       "3                             0.0                           0.0   \n",
       "4                             0.0                           0.0   \n",
       "...                           ...                           ...   \n",
       "74227                         0.0                           0.0   \n",
       "74228                         0.0                           0.0   \n",
       "74229                         0.0                           0.0   \n",
       "74230                         0.0                           0.0   \n",
       "74231                         0.0                           0.0   \n",
       "\n",
       "       make_TEMPLE ISLAND_nb  make_TEMPLE ISLAND_cash  make_GHD_nb  \\\n",
       "0                        0.0                      0.0          0.0   \n",
       "1                        0.0                      0.0          0.0   \n",
       "2                        0.0                      0.0          0.0   \n",
       "3                        0.0                      0.0          0.0   \n",
       "4                        0.0                      0.0          0.0   \n",
       "...                      ...                      ...          ...   \n",
       "74227                    0.0                      0.0          0.0   \n",
       "74228                    0.0                      0.0          0.0   \n",
       "74229                    0.0                      0.0          0.0   \n",
       "74230                    0.0                      0.0          0.0   \n",
       "74231                    0.0                      0.0          0.0   \n",
       "\n",
       "       make_GHD_cash  amount  \n",
       "0                0.0  1197.0  \n",
       "1                0.0  1635.0  \n",
       "2                0.0  2639.0  \n",
       "3                0.0  1873.0  \n",
       "4                0.0  1249.0  \n",
       "...              ...     ...  \n",
       "74227            0.0   900.0  \n",
       "74228            0.0  1699.0  \n",
       "74229            0.0   369.0  \n",
       "74230            0.0  1407.0  \n",
       "74231            0.0  2598.0  \n",
       "\n",
       "[74232 rows x 1982 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = add_amounts(X_train, verbose=verbose)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>Nb_of_items</th>\n",
       "      <th>item_BED LINEN_nb</th>\n",
       "      <th>item_BED LINEN_cash</th>\n",
       "      <th>item_BATHROOM_nb</th>\n",
       "      <th>item_BATHROOM_cash</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_nb</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_cash</th>\n",
       "      <th>item_TOYS_nb</th>\n",
       "      <th>...</th>\n",
       "      <th>make_BLUEBELLA_cash</th>\n",
       "      <th>make_ROLSER_nb</th>\n",
       "      <th>make_ROLSER_cash</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_nb</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_cash</th>\n",
       "      <th>make_TEMPLE ISLAND_nb</th>\n",
       "      <th>make_TEMPLE ISLAND_cash</th>\n",
       "      <th>make_GHD_nb</th>\n",
       "      <th>make_GHD_cash</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46180</td>\n",
       "      <td>107424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25031</td>\n",
       "      <td>74645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32798</td>\n",
       "      <td>102653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38656</td>\n",
       "      <td>23831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16271</td>\n",
       "      <td>60691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18553</th>\n",
       "      <td>14569</td>\n",
       "      <td>96137</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18554</th>\n",
       "      <td>70048</td>\n",
       "      <td>84464</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18555</th>\n",
       "      <td>39431</td>\n",
       "      <td>62549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2849.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18556</th>\n",
       "      <td>34291</td>\n",
       "      <td>89894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18557</th>\n",
       "      <td>35360</td>\n",
       "      <td>64654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1599.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18558 rows × 1982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index      ID  Nb_of_items  item_BED LINEN_nb  item_BED LINEN_cash  \\\n",
       "0      46180  107424          1.0                0.0                  0.0   \n",
       "1      25031   74645          1.0                0.0                  0.0   \n",
       "2      32798  102653          1.0                0.0                  0.0   \n",
       "3      38656   23831          1.0                0.0                  0.0   \n",
       "4      16271   60691          1.0                0.0                  0.0   \n",
       "...      ...     ...          ...                ...                  ...   \n",
       "18553  14569   96137          2.0                0.0                  0.0   \n",
       "18554  70048   84464          2.0                0.0                  0.0   \n",
       "18555  39431   62549          1.0                0.0                  0.0   \n",
       "18556  34291   89894          1.0                0.0                  0.0   \n",
       "18557  35360   64654          1.0                0.0                  0.0   \n",
       "\n",
       "       item_BATHROOM_nb  item_BATHROOM_cash  \\\n",
       "0                   0.0                 0.0   \n",
       "1                   0.0                 0.0   \n",
       "2                   0.0                 0.0   \n",
       "3                   0.0                 0.0   \n",
       "4                   0.0                 0.0   \n",
       "...                 ...                 ...   \n",
       "18553               0.0                 0.0   \n",
       "18554               0.0                 0.0   \n",
       "18555               0.0                 0.0   \n",
       "18556               0.0                 0.0   \n",
       "18557               0.0                 0.0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_nb  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "18553                                   0.0   \n",
       "18554                                   0.0   \n",
       "18555                                   0.0   \n",
       "18556                                   0.0   \n",
       "18557                                   0.0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_cash  item_TOYS_nb  ...  \\\n",
       "0                                         0.0           0.0  ...   \n",
       "1                                         0.0           0.0  ...   \n",
       "2                                         0.0           0.0  ...   \n",
       "3                                         0.0           0.0  ...   \n",
       "4                                         0.0           0.0  ...   \n",
       "...                                       ...           ...  ...   \n",
       "18553                                     0.0           0.0  ...   \n",
       "18554                                     0.0           0.0  ...   \n",
       "18555                                     0.0           0.0  ...   \n",
       "18556                                     0.0           0.0  ...   \n",
       "18557                                     0.0           0.0  ...   \n",
       "\n",
       "       make_BLUEBELLA_cash  make_ROLSER_nb  make_ROLSER_cash  \\\n",
       "0                      0.0             0.0               0.0   \n",
       "1                      0.0             0.0               0.0   \n",
       "2                      0.0             0.0               0.0   \n",
       "3                      0.0             0.0               0.0   \n",
       "4                      0.0             0.0               0.0   \n",
       "...                    ...             ...               ...   \n",
       "18553                  0.0             0.0               0.0   \n",
       "18554                  0.0             0.0               0.0   \n",
       "18555                  0.0             0.0               0.0   \n",
       "18556                  0.0             0.0               0.0   \n",
       "18557                  0.0             0.0               0.0   \n",
       "\n",
       "       make_DARTINGTON CRYSTAL_nb  make_DARTINGTON CRYSTAL_cash  \\\n",
       "0                             0.0                           0.0   \n",
       "1                             0.0                           0.0   \n",
       "2                             0.0                           0.0   \n",
       "3                             0.0                           0.0   \n",
       "4                             0.0                           0.0   \n",
       "...                           ...                           ...   \n",
       "18553                         0.0                           0.0   \n",
       "18554                         0.0                           0.0   \n",
       "18555                         0.0                           0.0   \n",
       "18556                         0.0                           0.0   \n",
       "18557                         0.0                           0.0   \n",
       "\n",
       "       make_TEMPLE ISLAND_nb  make_TEMPLE ISLAND_cash  make_GHD_nb  \\\n",
       "0                        0.0                      0.0          0.0   \n",
       "1                        0.0                      0.0          0.0   \n",
       "2                        0.0                      0.0          0.0   \n",
       "3                        0.0                      0.0          0.0   \n",
       "4                        0.0                      0.0          0.0   \n",
       "...                      ...                      ...          ...   \n",
       "18553                    0.0                      0.0          0.0   \n",
       "18554                    0.0                      0.0          0.0   \n",
       "18555                    0.0                      0.0          0.0   \n",
       "18556                    0.0                      0.0          0.0   \n",
       "18557                    0.0                      0.0          0.0   \n",
       "\n",
       "       make_GHD_cash  amount  \n",
       "0                0.0   499.0  \n",
       "1                0.0  1100.0  \n",
       "2                0.0  1187.0  \n",
       "3                0.0   479.0  \n",
       "4                0.0  1199.0  \n",
       "...              ...     ...  \n",
       "18553            0.0  2610.0  \n",
       "18554            0.0  1419.0  \n",
       "18555            0.0  2849.0  \n",
       "18556            0.0  2499.0  \n",
       "18557            0.0  1599.0  \n",
       "\n",
       "[18558 rows x 1982 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = add_amounts(X_test, verbose=verbose)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>Nb_of_items</th>\n",
       "      <th>item_BED LINEN_nb</th>\n",
       "      <th>item_BED LINEN_cash</th>\n",
       "      <th>item_BATHROOM_nb</th>\n",
       "      <th>item_BATHROOM_cash</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_nb</th>\n",
       "      <th>item_DISPOSABLE TABLEWARE CUTLERY_cash</th>\n",
       "      <th>item_TOYS_nb</th>\n",
       "      <th>...</th>\n",
       "      <th>make_BLUEBELLA_cash</th>\n",
       "      <th>make_ROLSER_nb</th>\n",
       "      <th>make_ROLSER_cash</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_nb</th>\n",
       "      <th>make_DARTINGTON CRYSTAL_cash</th>\n",
       "      <th>make_TEMPLE ISLAND_nb</th>\n",
       "      <th>make_TEMPLE ISLAND_cash</th>\n",
       "      <th>make_GHD_nb</th>\n",
       "      <th>make_GHD_cash</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>85517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>51113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>83008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>78712</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>77846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92785</th>\n",
       "      <td>0</td>\n",
       "      <td>21243</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92786</th>\n",
       "      <td>0</td>\n",
       "      <td>45891</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92787</th>\n",
       "      <td>0</td>\n",
       "      <td>42613</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1727.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92788</th>\n",
       "      <td>0</td>\n",
       "      <td>43567</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92789</th>\n",
       "      <td>0</td>\n",
       "      <td>68268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>799.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92790 rows × 1982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     ID  Nb_of_items  item_BED LINEN_nb  item_BED LINEN_cash  \\\n",
       "index                                                                      \n",
       "0          0  85517          1.0                0.0                  0.0   \n",
       "1          0  51113          1.0                0.0                  0.0   \n",
       "2          0  83008          1.0                0.0                  0.0   \n",
       "3          0  78712          2.0                0.0                  0.0   \n",
       "4          0  77846          1.0                0.0                  0.0   \n",
       "...      ...    ...          ...                ...                  ...   \n",
       "92785      0  21243          2.0                0.0                  0.0   \n",
       "92786      0  45891          1.0                0.0                  0.0   \n",
       "92787      0  42613          3.0                0.0                  0.0   \n",
       "92788      0  43567          2.0                0.0                  0.0   \n",
       "92789      0  68268          1.0                0.0                  0.0   \n",
       "\n",
       "       item_BATHROOM_nb  item_BATHROOM_cash  \\\n",
       "index                                         \n",
       "0                   0.0                 0.0   \n",
       "1                   0.0                 0.0   \n",
       "2                   0.0                 0.0   \n",
       "3                   0.0                 0.0   \n",
       "4                   0.0                 0.0   \n",
       "...                 ...                 ...   \n",
       "92785               0.0                 0.0   \n",
       "92786               0.0                 0.0   \n",
       "92787               0.0                 0.0   \n",
       "92788               0.0                 0.0   \n",
       "92789               0.0                 0.0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_nb  \\\n",
       "index                                         \n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "92785                                   0.0   \n",
       "92786                                   0.0   \n",
       "92787                                   0.0   \n",
       "92788                                   0.0   \n",
       "92789                                   0.0   \n",
       "\n",
       "       item_DISPOSABLE TABLEWARE CUTLERY_cash  item_TOYS_nb  ...  \\\n",
       "index                                                        ...   \n",
       "0                                         0.0           0.0  ...   \n",
       "1                                         0.0           0.0  ...   \n",
       "2                                         0.0           0.0  ...   \n",
       "3                                         0.0           0.0  ...   \n",
       "4                                         0.0           0.0  ...   \n",
       "...                                       ...           ...  ...   \n",
       "92785                                     0.0           0.0  ...   \n",
       "92786                                     0.0           0.0  ...   \n",
       "92787                                     0.0           0.0  ...   \n",
       "92788                                     0.0           0.0  ...   \n",
       "92789                                     0.0           0.0  ...   \n",
       "\n",
       "       make_BLUEBELLA_cash  make_ROLSER_nb  make_ROLSER_cash  \\\n",
       "index                                                          \n",
       "0                      0.0             0.0               0.0   \n",
       "1                      0.0             0.0               0.0   \n",
       "2                      0.0             0.0               0.0   \n",
       "3                      0.0             0.0               0.0   \n",
       "4                      0.0             0.0               0.0   \n",
       "...                    ...             ...               ...   \n",
       "92785                  0.0             0.0               0.0   \n",
       "92786                  0.0             0.0               0.0   \n",
       "92787                  0.0             0.0               0.0   \n",
       "92788                  0.0             0.0               0.0   \n",
       "92789                  0.0             0.0               0.0   \n",
       "\n",
       "       make_DARTINGTON CRYSTAL_nb  make_DARTINGTON CRYSTAL_cash  \\\n",
       "index                                                             \n",
       "0                             0.0                           0.0   \n",
       "1                             0.0                           0.0   \n",
       "2                             0.0                           0.0   \n",
       "3                             0.0                           0.0   \n",
       "4                             0.0                           0.0   \n",
       "...                           ...                           ...   \n",
       "92785                         0.0                           0.0   \n",
       "92786                         0.0                           0.0   \n",
       "92787                         0.0                           0.0   \n",
       "92788                         0.0                           0.0   \n",
       "92789                         0.0                           0.0   \n",
       "\n",
       "       make_TEMPLE ISLAND_nb  make_TEMPLE ISLAND_cash  make_GHD_nb  \\\n",
       "index                                                                \n",
       "0                        0.0                      0.0          0.0   \n",
       "1                        0.0                      0.0          0.0   \n",
       "2                        0.0                      0.0          0.0   \n",
       "3                        0.0                      0.0          0.0   \n",
       "4                        0.0                      0.0          0.0   \n",
       "...                      ...                      ...          ...   \n",
       "92785                    0.0                      0.0          0.0   \n",
       "92786                    0.0                      0.0          0.0   \n",
       "92787                    0.0                      0.0          0.0   \n",
       "92788                    0.0                      0.0          0.0   \n",
       "92789                    0.0                      0.0          0.0   \n",
       "\n",
       "       make_GHD_cash  amount  \n",
       "index                         \n",
       "0                0.0   889.0  \n",
       "1                0.0   409.0  \n",
       "2                0.0  1399.0  \n",
       "3                0.0   808.0  \n",
       "4                0.0  1199.0  \n",
       "...              ...     ...  \n",
       "92785            0.0   306.0  \n",
       "92786            0.0   898.0  \n",
       "92787            0.0  1727.0  \n",
       "92788            0.0  3198.0  \n",
       "92789            0.0   799.0  \n",
       "\n",
       "[92790 rows x 1982 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_origin = add_amounts(test_origin, verbose=verbose)\n",
    "test_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for over_name in OVERED_DATASET_FILE_NAME.keys():\n",
    "    # Modèle\tFeatures\tAdd Data\n",
    "    run_logistic = scores[(scores[\"Add Data\"] == over_name)&(scores[\"Modèle\"] == \"LogisticRegression\")].shape[0] == 0\n",
    "    run_sqbmc    = scores[(scores[\"Add Data\"] == over_name)&(scores[\"Modèle\"] == \"LGBMClassifier\")].shape[0] == 0\n",
    "\n",
    "    if run_logistic or run_sqbmc:\n",
    "        print(f\"{over_name} logistic = {run_logistic} and sqbmc = {run_sqbmc} \\t{surligne_text('processing...', 'blue')}\")\n",
    "        # Chargement des données\n",
    "        file_name = OVERED_DATASET_FILE_NAME.get(over_name)\n",
    "        \n",
    "        path = join(data_set_path,file_name)\n",
    "        if exists(path):\n",
    "            dataset_over = load_over_dataset(path, verbose=verbose)\n",
    "                        \n",
    "            if dataset_over is not None:\n",
    "                print(f\"{over_name} \\t ---> {surligne_text('pre-processing...', 'blue')}\")\n",
    "                \n",
    "                dataset_over = add_amounts(x_df_input=dataset_over, verbose=verbose)\n",
    "                y_train_over = complete_y_cols(dataset_over, y_param=dataset_over[target])\n",
    "                X_train_over = dataset_over.drop(target, axis=1)\n",
    "\n",
    "                dataset_dict_over['X_train'] = X_train_over\n",
    "                dataset_dict_over['y_train'] = y_train_over\n",
    "\n",
    "                if run_logistic:\n",
    "                    try:\n",
    "                        model, n_scores = train_LogisticRegression(dataset_dict=dataset_dict_over, data_set_path=data_set_path, \n",
    "                                        scores=scores, score_path=score_path, \n",
    "                                        features=\"ALL\", add_data=over_name,\n",
    "                                        verbose=verbose)\n",
    "                        save_score(n_scores, score_path=score_path)\n",
    "                        scores = n_scores\n",
    "                        print(f\"{over_name} processing logistic = \\t{surligne_text('DONE')}\")\n",
    "                    except Exception as error:\n",
    "                        print(f\"{over_name} processing logistic = \\t{surligne_text('FAIL', 'red')} : {error}\")\n",
    "                \n",
    "                if run_sqbmc:\n",
    "                    try:\n",
    "                        lgb_classifier, n_scores = train_LGBMClassifier(dataset_dict=dataset_dict_over, data_set_path=data_set_path, \n",
    "                                        scores=scores, score_path=score_path, \n",
    "                                        features=\"ALL\",  add_data=over_name,\n",
    "                                        verbose=verbose)\n",
    "                        save_score(n_scores, score_path=score_path)\n",
    "                        scores = n_scores\n",
    "                        print(f\"{over_name} processing sqbmc = \\t{surligne_text('DONE')}\")\n",
    "                    except Exception as error:\n",
    "                        print(f\"{over_name} processing sqbmc = \\t{surligne_text('FAIL', 'red')} : {error}\")\n",
    "    else:\n",
    "        print(f\"{over_name} \\t\\t {surligne_text('DONE')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa1a338178f9f930bee8bd77ef02489fdd5066fc93282fb64038484aff075692"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
